import asyncio
from unittest.mock import AsyncMock, MagicMock
from datetime import datetime
from src.r_core.hippocampus import Hippocampus
from src.r_core.infrastructure.db import ChatHistoryModel, VolitionalModel

# --- Mocks ---

class MockLLM:
    async def complete(self, prompt: str) -> str:
        print(f"\n[MockLLM] Prompt received:\n{prompt[:100]}...\n")
        # Simulate extraction for "I want to learn Spanish but I'm lazy"
        return """
        [
          {
            "trigger": "discussion about learning",
            "impulse": "laziness",
            "target": "Spanish",
            "resolution_strategy": "promise to try later",
            "intensity": 0.6,
            "fuel": 0.4
          }
        ]
        """

class MockEmbedder:
    async def embed(self, text: str):
        return [0.1, 0.2, 0.3]

# --- Test Runner ---

async def run_test():
    print("üöÄ Starting Semantic Intent Analysis Test (Mocked)...")
    
    # 1. Setup
    llm = MockLLM()
    embedder = MockEmbedder()
    hippo = Hippocampus(llm_client=llm, embedding_client=embedder)
    
    # 2. Mock DB Session and Data
    # We need to monkeypatch the AsyncSessionLocal used inside Hippocampus
    # OR we can just test the internal logic if we refactor, but here we'll mock the db call context.
    
    # Since we can't easily mock the internal AsyncSessionLocal context manager without 
    # complex patching, we will assume the user runs this in an env where DB is accessible
    # OR we demonstrate the logic by extracting the LLM part which is the core change.
    
    # Let's test the LLM extraction part specifically, which is isolated.
    
    messages = [
        ChatHistoryModel(role="user", content="–ü—Ä–∏–≤–µ—Ç"),
        ChatHistoryModel(role="assistant", content="–ü—Ä–∏–≤–µ—Ç!"),
        ChatHistoryModel(role="user", content="–•–æ—á—É –≤—ã—É—á–∏—Ç—å –∏—Å–ø–∞–Ω—Å–∫–∏–π, –Ω–æ –º–Ω–µ —Ç–∞–∫ –ª–µ–Ω—å..."),
        ChatHistoryModel(role="assistant", content="–ú–æ–∂–µ—Ç –Ω–∞—á–Ω–µ—à—å —Å –º–∞–ª–æ–≥–æ?"),
        ChatHistoryModel(role="user", content="–ù—É –ª–∞–¥–Ω–æ, –ø–æ–ø—Ä–æ–±—É—é –∑–∞–≤—Ç—Ä–∞ 5 –º–∏–Ω—É—Ç.")
    ]
    
    print("\nüìù Analysing Dialogue:")
    for m in messages:
        print(f" - {m.role}: {m.content}")
        
    # Test private method _llm_extract_volitional_intent directly
    patterns = await hippo._llm_extract_volitional_intent(messages)
    
    print("\n‚úÖ Result Patterns:")
    for p in patterns:
        print(p)
        
    assert len(patterns) == 1
    assert patterns[0]['target'] == "Spanish"
    assert patterns[0]['impulse'] == "laziness"
    print("\nüéâ Test Passed!")

if __name__ == "__main__":
    asyncio.run(run_test())

# Fine-Tuning Roadmap –¥–ª—è R-Bot Council

> **–°—Ç–∞—Ç—É—Å:** –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞  
> **–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è Council Report, –Ω–µ–∑–∞–≤–∏—Å–∏–º—É—é –æ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ø—É–±–ª–∏—á–Ω—ã—Ö LLM  
> **–î–∞—Ç–∞:** 09.02.2026

---

## üéØ –ü—Ä–æ–±–ª–µ–º–∞

### –¢–µ–∫—É—â–∞—è —Å–∏—Ç—É–∞—Ü–∏—è:
- Council Report (scoring –º–æ–∑–≥–æ–≤—ã—Ö –º–æ–¥—É–ª–µ–π) **–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤—ã–±–æ—Ä–∞ LLM**
- –†–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–∞—é—Ç **—Ä–∞–∑–Ω—ã–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏** –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:

| –ú–æ–¥–µ–ª—å | –ó–∞–ø—Ä–æ—Å: "–ö—Ç–æ —Ç—ã?" | Winner | –ü—Ä–æ–±–ª–µ–º–∞ |
|--------|-------------------|--------|----------|
| Claude Haiku 3/4.5 | –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å | `amygdala`/`striatum` | ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ |
| DeepSeek V3.1 | –õ–æ–≥–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å | `prefrontal_logic` | ‚ùå –°–ª–∏—à–∫–æ–º "—Ä–æ–±–æ—Ç" |
| Gemini Flash | –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å | `prefrontal_logic` | ‚ùå –°—É—Ö–æ |

### –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:
- ‚ùå –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –º–µ–Ω—è—é—Ç "–ª–∏—á–Ω–æ—Å—Ç—å" –ø—Ä–∏ —Å–º–µ–Ω–µ –º–æ–¥–µ–ª–∏
- ‚ùå –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ scoring (prefrontal –∑–∞–≤—ã—à–∞–µ—Ç—Å—è, amygdala –∑–∞–Ω–∏–∂–∞–µ—Ç—Å—è)
- ‚ùå –û—Ç–≤–µ—Ç—ã —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è "—Ä–æ–±–æ—Ç–∏—á–Ω—ã–º–∏" –Ω–∞ –¥–µ—à—ë–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö

---

## üí° –†–µ—à–µ–Ω–∏–µ: Fine-Tuning —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### –ò–¥–µ—è:
–û–±—É—á–∏—Ç—å **–º–∞–ª–µ–Ω—å–∫—É—é —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å** (1.5B-7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) **—Ç–æ–ª—å–∫–æ –¥–ª—è Council Report**.

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- ‚úÖ **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å:** –ú–æ–¥–µ–ª—å –Ω–µ –∏–∑–º–µ–Ω–∏—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
- ‚úÖ **–¢–æ—á–Ω–æ—Å—Ç—å:** –û–±—É—á–µ–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –Ω–∞ —Ç–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ **–ö–æ–Ω—Ç—Ä–æ–ª—å:** –ú–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∞—Ç—å –Ω–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
- ‚úÖ **–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å:** –ù–µ –∑–∞–≤–∏—Å–∏–º –æ—Ç OpenAI/Anthropic/DeepSeek
- ‚úÖ **–°–∫–æ—Ä–æ—Å—Ç—å:** –ú–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å = –±—ã—Å—Ç—Ä–µ–µ inference

---

## üìã –ü–ª–∞–Ω Fine-Tuning

### –≠—Ç–∞–ø 1: –°–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞

**–¶–µ–ª—å:** 500-1000 –ø—Ä–∏–º–µ—Ä–æ–≤  
**–§–æ—Ä–º–∞—Ç (JSONL):**
```json
{"messages": [
  {"role": "system", "content": "You analyze user messages and output JSON with brain module scores."},
  {"role": "user", "content": "–ö—Ç–æ —Ç—ã?"},
  {"role": "assistant", "content": "{\"amygdala\": {\"score\": 7, \"rationale\": \"–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å\", \"confidence\": 0.9}, \"prefrontal\": {\"score\": 5, \"rationale\": \"–£–º–µ—Ä–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞\", \"confidence\": 0.8}, \"striatum\": {\"score\": 8, \"rationale\": \"–õ—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ\", \"confidence\": 0.9}}"}
]}
```

**–°–ø–æ—Å–æ–±—ã —Å–±–æ—Ä–∞:**
1. **–í—Ä—É—á–Ω—É—é** (—Ä–∞–∑–º–µ—Ç–∏—Ç—å 100 –ø—Ä–∏–º–µ—Ä–æ–≤)
2. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Claude** (–ø–æ–ø—Ä–æ—Å–∏—Ç—å Claude —Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ scores)
3. **–ò–∑ –ª–æ–≥–æ–≤** (–≤–∑—è—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π + –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∏—Ç—å scores)

**–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞:**
- –í–æ–ø—Ä–æ—Å—ã –æ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ ("–ö—Ç–æ —Ç—ã?", "–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ")
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã ("–ö–∞–∫ –¥–µ–ª–∞?", "–ü–æ–¥–¥–µ—Ä–∂–∏ –º–µ–Ω—è")
- –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ ("–û–±—ä—è—Å–Ω–∏, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç X")
- –ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã ("–ü—Ä–∏–¥—É–º–∞–π –∏—Å—Ç–æ—Ä–∏—é")
- –ù–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ç–µ–º—ã (—Ç–µ—Å—Ç—ã amygdala_safety)

---

### –≠—Ç–∞–ø 2: –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã

#### –í–∞—Ä–∏–∞–Ω—Ç A: OpenAI Fine-Tuning (–°–ê–ú–´–ô –ü–†–û–°–¢–û–ô)
- **–ú–æ–¥–µ–ª—å:** GPT-4o-mini
- **–¶–µ–Ω–∞:** ~$4 (~350‚ÇΩ) –∑–∞ –æ–±—É—á–µ–Ω–∏–µ
- **–í—Ä–µ–º—è:** 1-2 —á–∞—Å–∞
- **–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞:** –ù–µ –Ω—É–∂–Ω–∞ (–≤—Å—ë —á–µ—Ä–µ–∑ API)
- **Inference:** ~$0.012 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ (~1‚ÇΩ)

**–ö–æ–º–∞–Ω–¥—ã:**
```bash
openai api fine_tunes.create -t dataset.jsonl -m gpt-4o-mini
```

#### –í–∞—Ä–∏–∞–Ω—Ç B: Mac M1/M2 (8 GB RAM) ‚Äî –õ–æ–∫–∞–ª—å–Ω–æ
- **–ú–æ–¥–µ–ª—å:** Qwen2.5 1.5B (–≤–ª–µ–∑–µ—Ç –≤ 8 GB!)
- **–¶–µ–Ω–∞:** –ë–ï–°–ü–õ–ê–¢–ù–û
- **–í—Ä–µ–º—è:** 10-14 —á–∞—Å–æ–≤ (–æ–±—É—á–∞—Ç—å –Ω–æ—á—å—é)
- **–§—Ä–µ–π–º–≤–æ—Ä–∫:** MLX (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è Apple Silicon)

**–°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- Mac M1/M2/M3 —Å 8 GB unified memory
- ~15 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ SSD

**–ö–æ–¥:**
```python
from mlx_lm.tuner import train

train(
    model="mlx-community/Qwen2.5-1.5B-Instruct-4bit",
    data="dataset.jsonl",
    train=True,
    iters=1000,
    batch_size=1,
    lora_layers=16,
    learning_rate=1e-5,
    output_dir="./rbot_council_mlx"
)
```

#### –í–∞—Ä–∏–∞–Ω—Ç C: Vast.ai –∞—Ä–µ–Ω–¥–∞ GPU (CHEAPEST)
- **–ú–æ–¥–µ–ª—å:** Qwen2.5 7B (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
- **–¶–µ–Ω–∞:** ~$1-2 (RTX 3090 @ $0.20/—á–∞—Å)
- **–í—Ä–µ–º—è:** 2-4 —á–∞—Å–∞
- **–§—Ä–µ–π–º–≤–æ—Ä–∫:** Unsloth + LoRA

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** Qwen 7B –¥–∞—Å—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —á–µ–º 1.5B

---

### –≠—Ç–∞–ø 3: –û–±—É—á–µ–Ω–∏–µ

**–ú–µ—Ç–æ–¥:** LoRA (Low-Rank Adaptation)  
**–ü–ª—é—Å—ã:**
- –í 10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ full fine-tuning
- –ê–¥–∞–ø—Ç–µ—Ä—ã –≤–µ—Å—è—Ç 50-200 MB (–≤–º–µ—Å—Ç–æ 14 GB)
- –ù—É–∂–Ω–æ –º–µ–Ω—å—à–µ VRAM/RAM

**–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
```python
lora_rank = 16  # –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ
learning_rate = 2e-4
num_epochs = 3
batch_size = 2 (–∏–ª–∏ 1 –¥–ª—è 8GB Mac)
gradient_accumulation_steps = 4
```

---

### –≠—Ç–∞–ø 4: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

**Test set:** 100 –ø—Ä–∏–º–µ—Ä–æ–≤ (–æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç train)  
**–ú–µ—Ç—Ä–∏–∫–∏:**
1. **JSON validity rate** (–º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –≤–∞–ª–∏–¥–Ω—ã–π JSON)
2. **Score accuracy** (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç expected scores < 2 –±–∞–ª–ª–æ–≤)
3. **Module winner accuracy** (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω winner –º–æ–¥—É–ª—å)

**Benchmark:**
| –ú–µ—Ç—Ä–∏–∫–∞ | Claude Haiku 4.5 (baseline) | Fine-tuned Qwen 1.5B | Fine-tuned Qwen 7B |
|---------|----------------------------|----------------------|--------------------|
| JSON validity | 95% | ? | ? |
| Score MAE | 1.2 | ? | ? |
| Winner accuracy | 87% | ? | ? |

---

### –≠—Ç–∞–ø 5: –î–µ–ø–ª–æ–π

#### –î–ª—è OpenAI fine-tuned –º–æ–¥–µ–ª–∏:
```python
# src/r_core/llm.py
model_name = "ft:gpt-4o-mini:rbot::abc123"  # —Ç–≤–æ—è fine-tuned –º–æ–¥–µ–ª—å
```

#### –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (Qwen):
```python
from mlx_lm import load, generate

model, tokenizer = load("./rbot_council_mlx")
response = generate(model, tokenizer, prompt=user_input, max_tokens=256)
```

**–ò–ª–∏ —á–µ—Ä–µ–∑ Ollama:**
```bash
# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ Ollama
ollama create rbot-council -f ./Modelfile

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
curl http://localhost:11434/api/generate -d '{
  "model": "rbot-council",
  "prompt": "User: –ö—Ç–æ —Ç—ã?"
}'
```

---

## üí∏ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç

| –í–∞—Ä–∏–∞–Ω—Ç | –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è | Inference (–∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤) | –ò—Ç–æ–≥–æ (1 –≥–æ–¥, 10K –∑–∞–ø—Ä–æ—Å–æ–≤) |
|---------|-------------------|---------------------------|-----------------------------|
| **Claude Haiku 4.5** (baseline) | $0 | ~$0.50 | ~$5000 |
| **OpenAI Fine-tuned** | ~$4 | ~$0.012 | ~$124 |
| **Qwen 1.5B (Mac)** | **$0** | **$0** | **$0** |
| **Qwen 7B (Vast.ai)** | ~$2 | **$0** (–ª–æ–∫–∞–ª—å–Ω–æ) | **$2** |

**–≠–∫–æ–Ω–æ–º–∏—è:** –î–æ **$5000/–≥–æ–¥** –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å!

---

## üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞:
‚úÖ **OpenAI Fine-Tuning (GPT-4o-mini)**  
- –ì–æ—Ç–æ–≤–æ –∑–∞ 1 –¥–µ–Ω—å
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- –¶–µ–Ω–∞ —Ä–∞–∑—É–º–Ω–∞—è

### –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç–∫–æ–Ω–æ–º–∏–∏:
‚úÖ **Qwen 7B –Ω–∞ Vast.ai**  
- $2 –æ–¥–∏–Ω —Ä–∞–∑
- –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π inference –Ω–∞–≤—Å–µ–≥–¥–∞
- –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ

### –î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:
‚úÖ **Qwen 1.5B –Ω–∞ —Å–≤–æ—ë–º –ú–∞–∫–µ**  
- –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ
- –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å —Å–∫–æ–ª—å–∫–æ —É–≥–æ–¥–Ω–æ
- –ö–∞—á–µ—Å—Ç–≤–∞ —Ö–≤–∞—Ç–∏—Ç –¥–ª—è MVP

---

## üöÄ Next Steps

### –ö–æ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞—Ç—å:
- [x] –ó–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ
- [ ] –°–æ–±—Ä–∞—Ç—å –ø–µ—Ä–≤—ã–µ 100 –ø—Ä–∏–º–µ—Ä–æ–≤ –≤—Ä—É—á–Ω—É—é
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å OpenAI fine-tuning (–±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ—Ç–æ—Ç–∏–ø)
- [ ] –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ vs Claude Haiku
- [ ] –†–µ—à–∏—Ç—å: OpenAI –∏–ª–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π Qwen

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
- **–ù–∏–∑–∫–∏–π** (–ø–æ–∫–∞ Claude Haiku 4.5 —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ)
- **–ü–æ–≤—ã—à–∞–µ—Ç—Å—è**, –µ—Å–ª–∏:
  - Claude –Ω–∞—á–Ω—ë—Ç —Å–∏–ª—å–Ω–æ –¥–æ—Ä–æ–∂–∞—Ç—å
  - –ü–æ—è–≤—è—Ç—Å—è –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å—é API
  - –ù—É–∂–Ω–∞ –±–æ–ª—å—à–∞—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è scoring logic

---

## üìö –°—Å—ã–ª–∫–∏

- [OpenAI Fine-Tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)
- [MLX Examples (–¥–ª—è Mac)](https://github.com/ml-explore/mlx-examples/tree/main/llms)
- [Unsloth (fast LoRA)](https://github.com/unslothai/unsloth)
- [Vast.ai (GPU –∞—Ä–µ–Ω–¥–∞)](https://vast.ai)
- [Qwen2.5 Models](https://huggingface.co/Qwen)

---

**–ê–≤—Ç–æ—Ä:** AI Assistant (Perplexity)  
**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 09.02.2026  
**–°—Ç–∞—Ç—É—Å:** Draft / Roadmap

import asyncio
from typing import Dict, List, Optional
from datetime import datetime

from .schemas import (
    IncomingMessage, 
    CoreResponse, 
    CoreAction, 
    BotConfig, 
    ProcessingMode,
    AgentType,
    MoodVector,
    SemanticTriple,
    AgentSignal,
    HormonalState 
)
from .memory import MemorySystem
from .infrastructure.llm import LLMService
from .infrastructure.db import log_turn_metrics
from .agents import (
    IntuitionAgent,
    AmygdalaAgent,
    PrefrontalAgent,
    SocialAgent,
    StriatumAgent
)
from .neuromodulation import NeuroModulationSystem 

class RCoreKernel:
    # === ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢Ğ ===
    # Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ² council_report Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸.
    # Ğ Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒ: Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Hormonal Physics (NE, DA, 5-HT, CORT),
    # Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ council_report Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚, Ğ±ĞµĞ· ÑƒÑÑ€ĞµĞ´Ğ½ĞµĞ½Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸.
    COUNCIL_CONTEXT_DEPTH = 1  # 1 = Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ° (Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°)
                                # 2 = Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ° + Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞµ ÑĞ·ĞµÑ€Ğ°
                                # 3 = Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ¼Ğ¸Ğ½Ğ¸-Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºĞ° Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
    
    # === AFFECTIVE KEYWORDS ===
    # ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ, Ğ½ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ council (Ñ Affective Extraction).
    # Ğ•ÑĞ»Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ½Ğ¾ Ğ¸Ğ· ÑÑ‚Ğ¸Ñ… ÑĞ»Ğ¾Ğ² â†’ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ full mode.
    AFFECTIVE_KEYWORDS = [
        "Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ¶Ñƒ", "Ğ±Ğ¾ÑÑÑŒ", "Ğ»ÑĞ±Ğ»Ñ", "Ğ¾Ğ±Ğ¾Ğ¶Ğ°Ñ", "Ğ¿Ñ€ĞµĞ·Ğ¸Ñ€Ğ°Ñ", "Ñ‚ĞµÑ€Ğ¿ĞµÑ‚ÑŒ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ", "Ğ½Ğµ Ğ²Ñ‹Ğ½Ğ¾ÑˆÑƒ",
        "hate", "fear", "love", "enjoy", "despise", "adore", "can't stand"
    ]
    
    def __init__(self, config: BotConfig):
        self.config = config
        self.llm = LLMService() 
        self.memory = MemorySystem(store=None)
        
        # --- EHS: Internal State ---
        self.current_mood = MoodVector(valence=0.1, arousal=0.1, dominance=0.0) 
        
        # --- Neuro-Modulation System (Hormonal Physics) ---
        self.neuromodulation = NeuroModulationSystem()
        
        # Init agents
        self.agents = [
            IntuitionAgent(self.llm),
            AmygdalaAgent(self.llm),
            PrefrontalAgent(self.llm),
            SocialAgent(self.llm),
            StriatumAgent(self.llm)
        ]

    async def process_message(self, message: IncomingMessage, mode: str = "CORTICAL") -> CoreResponse:
        """
        Main pipeline entry point.
        mode="CORTICAL" -> Full cognitive architecture (RAG, Agents, Profiling).
        mode="ZOMBIE" -> Simple LLM pass-through (No memory, No personality).
        """
        start_time = datetime.now()
        
        # --- 0. Temporal Metabolism (Sense of Time) ---
        # Calculate delta_t and apply decay BEFORE any cognitive processing
        delta_minutes = self.neuromodulation.metabolize_time(message.timestamp)
        print(f"[Neuro] Time passed: {delta_minutes:.1f} min. New State: {self.neuromodulation.state}")
        
        # --- ZOMBIE MODE (Bypass Everything) ---
        if mode == "ZOMBIE":
            # Just call LLM directly without system prompt engineering or memory
            simple_response = await self.llm._safe_chat_completion(
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant. Answer concisely."},
                    {"role": "user", "content": message.text}
                ],
                response_format=None,
                json_mode=False
            )
            latency = (datetime.now() - start_time).total_seconds() * 1000
            
            return CoreResponse(
                actions=[CoreAction(type="send_text", payload={"text": str(simple_response)})],
                winning_agent=AgentType.PREFRONTAL, # Dummy
                current_mood=MoodVector(), # Neutral
                processing_mode=ProcessingMode.FAST_PATH,
                internal_stats={"latency_ms": int(latency), "mode": "ZOMBIE"}
            )

        # --- CORTICAL MODE (Full Architecture) ---
        
        # 0. Precompute Embedding
        current_embedding = None
        try:
            current_embedding = await self.llm.get_embedding(message.text)
        except Exception as e:
            print(f"[Pipeline] Embedding failed early: {e}")
        
        # 1. Perception
        perception_task = self._mock_perception(message)
        
        # 2. Retrieval 
        context = await self.memory.recall_context(
            message.user_id, 
            message.text, 
            session_id=message.session_id,
            precomputed_embedding=current_embedding
        )
        
        user_profile = context.get("user_profile", {})
        
        # === FIX: Normalize user mode (DB has "Ñ‚Ñ‹", code expects "informal") ===
        raw_mode = user_profile.get("preferred_mode", "formal") if user_profile else "formal"
        if raw_mode and raw_mode.lower() in ["Ñ‚Ñ‹", "informal", "casual", "friendly"]:
            preferred_mode = "informal"
        else:
            preferred_mode = "formal"
            
        print(f"[Pipeline] Mode Normalized: '{raw_mode}' -> '{preferred_mode}'")

        # Save memory
        extraction_result = await perception_task
        await self.memory.memorize_event(
            message, 
            extraction_result,
            precomputed_embedding=current_embedding
        )

        # 3. Parliament Debate
        # Council: Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· COUNCIL_CONTEXT_DEPTH)
        council_context_str = self._format_context_for_llm(
            context, 
            limit_history=self.COUNCIL_CONTEXT_DEPTH,
            exclude_episodic=True,   # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ episodic memory Ğ¸Ğ· council (Ğ½Ğµ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²)
            exclude_semantic=True    # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ semantic facts Ğ¸Ğ· council (Ğ½Ğµ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²)
        )
        
        # âœ¨ Conditional Council Mode: Light (95%) vs Full (5%)
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹ Ğ² ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¸
        has_affective = any(keyword in message.text.lower() for keyword in self.AFFECTIVE_KEYWORDS)
        
        if has_affective:
            print("[Council] Using FULL mode (Affective Extraction enabled)")
            council_report = await self.llm.generate_council_report_full(message.text, council_context_str)
        else:
            print("[Council] Using LIGHT mode (agents only)")
            council_report = await self.llm.generate_council_report_light(message.text, council_context_str)
        
        # âœ¨ Affective Extraction Processing (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ±Ñ‹Ğ» full mode)
        affective_extracts = council_report.get("affective_extraction", [])
        affective_triggers_count = 0
        
        if affective_extracts:
            print(f"[Affective ToM] Detected {len(affective_extracts)} emotional relations")
            for item in affective_extracts:
                # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ intensity Ğ² VAD-Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
                intensity = item.get("intensity", 0.5)
                predicate = item.get("predicate", "UNKNOWN")
                
                # Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ valence Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ predicate
                if predicate in ["HATES", "DESPISES", "FEARS"]:
                    valence = -intensity
                elif predicate in ["LOVES", "ENJOYS", "ADORES"]:
                    valence = intensity
                else:
                    valence = 0.0
                
                sentiment_vad = {
                    "valence": valence,
                    "arousal": 0.5 if predicate == "FEARS" else 0.3,  # Ğ¡Ñ‚Ñ€Ğ°Ñ… Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ arousal
                    "dominance": -0.2 if predicate == "FEARS" else 0.0
                }
                
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ğ³Ñ€Ğ°Ñ„ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
                triple = SemanticTriple(
                    subject=item.get("subject", "User"),
                    predicate=predicate,
                    object=item.get("object", ""),
                    confidence=intensity,
                    source_message_id=message.message_id,
                    sentiment=sentiment_vad
                )
                
                await self.memory.store.save_semantic(message.user_id, triple)
                affective_triggers_count += 1
                print(f"[Affective ToM] Saved: {triple.subject} {triple.predicate} {triple.object} (valence={valence:.2f})")
        
        # âœ¨ Feature Flag - Unified Council vs Legacy
        if self.config.use_unified_council:
            # NEW LOGIC: All agents processed through council_report (including Intuition)
            signals = self._process_unified_council(council_report, message, context)
            print(f"[Pipeline] Using UNIFIED COUNCIL mode (intuition_gain={self.config.intuition_gain})")
        else:
            # OLD LOGIC: Intuition processed separately
            signals = await self._process_legacy_council(council_report, message, context)
            print(f"[Pipeline] Using LEGACY mode (Intuition evaluated separately)")

        # âœ¨ Apply Hormonal Modulation BEFORE arbitration
        signals = self._apply_hormonal_modulation(signals)

        # 4. Arbitration & Mood Update
        signals.sort(key=lambda s: s.score, reverse=True)
        winner = signals[0]
        
        # --- Neuro-Modulation (Adverbs) ---
        # Strong Losers: Score > 5.0 AND not the winner
        strong_losers = [s for s in signals if s.score > 5.0 and s.agent_name != winner.agent_name]
        
        adverb_instructions = []
        for loser in strong_losers:
            if loser.style_instruction:
                adverb_instructions.append(f"- {loser.agent_name.name}: {loser.style_instruction}")
        
        adverb_context_str = ""
        if adverb_instructions:
            adverb_context_str = "\\nSECONDARY STYLE MODIFIERS (Neuro-Modulation):\\n" + "\\n".join(adverb_instructions)
            print(f"[Neuro-Modulation] Applied styles from: {[s.agent_name for s in strong_losers]}")
        
        # --- Hormonal Reactive Update ---
        # Update hormones based on who won and implicit Prediction Error
        # TODO: Implement real PE calculation. For now, infer from winner.
        implied_pe = 0.5
        if winner.agent_name == AgentType.AMYGDALA: implied_pe = 0.9 # Threat = Surprise
        elif winner.agent_name == AgentType.INTUITION: implied_pe = 0.2 # Intuition = High Confidence match
        elif winner.agent_name == AgentType.STRIATUM: implied_pe = 0.1 # Reward = Everything good
        
        self.neuromodulation.update_from_stimuli(implied_pe, winner.agent_name)
        
        # NEW: Update VAD Mood directly from Hormones (Physics consistency)
        self._update_mood_from_hormones()
        
        all_scores = {s.agent_name.value: round(s.score, 2) for s in signals}
        
        # 5. Response Generation (Inject Mood Styles)
        # Response: Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Ğ±ĞµĞ· Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹, Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°)
        response_context_str = self._format_context_for_llm(context)

        bot_gender = getattr(self.config, "gender", "Neutral")
        
        # --- STYLE GENERATION ---
        # 1. Semantic Style (Archetype) - WHAT to play (e.g. "Aggressive")
        mechanical_style_instruction = self.neuromodulation.get_style_instruction()
        
        # 2. Syntactic Style (VAD) - HOW to play (e.g. "Short sentences")
        vad_technical_instruction = self._generate_style_from_mood(self.current_mood)
        
        # Combine: Archetype + VAD Constraints + Agent Adverbs
        final_style_instructions = (
            f"{mechanical_style_instruction}\n"
            f"SYNTAX & PACING CONTROLS (VAD System):\n"
            f"{vad_technical_instruction}\n"
            f"{adverb_context_str}"
        )
        
        # âœ¨ Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ affective_context_str Ğ¸Ğ· context["affective_context"]
        affective_warnings = context.get("affective_context", [])
        affective_context_str = ""
        
        if affective_warnings:
            affective_context_str = "âš ï¸ EMOTIONAL RELATIONS (User's Preferences):\\n"
            for warn in affective_warnings:
                entity = warn["entity"]
                predicate = warn["predicate"]
                feeling = warn["user_feeling"]
                intensity = warn["intensity"]
                
                if feeling == "NEGATIVE":
                    affective_context_str += f"- âš ï¸ AVOID mentioning '{entity}' (User {predicate} it, intensity={intensity:.2f}). Do not use it as an example.\\n"
                else:
                    affective_context_str += f"- ğŸ’š User {predicate} '{entity}' (intensity={intensity:.2f}). You may reference it positively.\\n"
        
        response_text = await self.llm.generate_response(
            agent_name=winner.agent_name.value,
            user_text=message.text,
            context_str=response_context_str,  # Full context for response generation
            rationale=winner.rationale_short,
            bot_name=self.config.name,
            bot_gender=bot_gender,
            user_mode=preferred_mode,
            style_instructions=final_style_instructions,  # Pass combined styles
            affective_context=affective_context_str
        )
        
        await self.memory.memorize_bot_response(
            message.user_id, 
            message.session_id, 
            response_text
        )
        
        latency = (datetime.now() - start_time).total_seconds() * 1000
        
        internal_stats = {
            "latency_ms": int(latency),
            "winner_score": winner.score,
            "winner_reason": winner.rationale_short,
            "all_scores": all_scores,
            "mood_state": str(self.current_mood),
            "hormonal_state": str(self.neuromodulation.state), # Log hormones
            "hormonal_archetype": self.neuromodulation.get_archetype(),
            "active_style": final_style_instructions,
            "affective_triggers_detected": affective_triggers_count,
            "sentiment_context_used": bool(affective_warnings),
            "modulators": [s.agent_name.value for s in strong_losers],
            "mode": "UNIFIED" if self.config.use_unified_council else "LEGACY",
            "intuition_gain": self.config.intuition_gain,
            "council_context_depth": self.COUNCIL_CONTEXT_DEPTH,  # Log for analytics
            "council_mode": "FULL" if has_affective else "LIGHT"  # NEW: Track council mode
        }

        await log_turn_metrics(message.user_id, message.session_id, internal_stats)
        
        return CoreResponse(
            actions=[
                CoreAction(type="send_text", payload={"text": response_text})
            ],
            winning_agent=winner.agent_name,
            current_mood=self.current_mood, 
            current_hormones=self.neuromodulation.state, # Pass to UI
            processing_mode=ProcessingMode.SLOW_PATH,
            internal_stats=internal_stats
        )

    def _apply_hormonal_modulation(self, signals: List[AgentSignal]) -> List[AgentSignal]:
        """
        ĞœĞ¾Ğ´ÑƒĞ»Ğ¸Ñ€ÑƒĞµÑ‚ Scores Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ³Ğ¾Ñ€Ğ¼Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ñ€Ñ…ĞµÑ‚Ğ¸Ğ¿Ğ°.
        ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ´Ğ»Ñ ÑĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹ (RAGE, FEAR, BURNOUT, SHAME, TRIUMPH).
        
        Returns: Modified list of AgentSignals.
        """
        archetype = self.neuromodulation.get_archetype()
        
        # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ´Ğ»Ñ ÑĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¹
        MODULATION_MAP = {
            "RAGE": {
                AgentType.AMYGDALA: 1.6,
                AgentType.PREFRONTAL: 0.6,
                AgentType.SOCIAL: 0.8
            },
            "FEAR": {
                AgentType.AMYGDALA: 1.8,
                AgentType.STRIATUM: 0.4,
                AgentType.PREFRONTAL: 0.7
            },
            "BURNOUT": {
                AgentType.PREFRONTAL: 0.3,
                AgentType.INTUITION: 1.5,
                AgentType.AMYGDALA: 1.2
            },
            "SHAME": {
                AgentType.INTUITION: 1.3
                # Ğ’ÑĞµ Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ: 0.8 (ÑĞ¼. Ğ½Ğ¸Ğ¶Ğµ)
            },
            "TRIUMPH": {
                AgentType.STRIATUM: 1.3,
                AgentType.AMYGDALA: 0.5,
                AgentType.PREFRONTAL: 1.1
            }
        }
        
        if archetype not in MODULATION_MAP:
            # ĞĞµ ÑĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ â†’ Ğ±ĞµĞ· Ğ¼Ğ¾Ğ´ÑƒĞ»ÑÑ†Ğ¸Ğ¸
            return signals
        
        print(f"[Hormonal Override] {archetype} is modulating agent scores")
        
        modifiers = MODULATION_MAP[archetype]
        default_mod = 0.8 if archetype == "SHAME" else 1.0
        
        for signal in signals:
            mod = modifiers.get(signal.agent_name, default_mod)
            old_score = signal.score
            signal.score *= mod
            signal.score = max(0.0, min(10.0, signal.score))  # Clamp to [0, 10]
            
            if mod != 1.0:
                print(f"  - {signal.agent_name.name}: {old_score:.2f} â†’ {signal.score:.2f} (Ã—{mod})")
        
        return signals

    def _process_unified_council(self, council_report: Dict, message: IncomingMessage, context: Dict) -> List[AgentSignal]:
        """
        âœ¨ NEW: Unified processing - all 5 agents evaluated by LLM together.
        Intuition score is multiplied by intuition_gain.
        """
        signals = []
        
        agent_map = {
            "intuition": (self.agents[0], AgentType.INTUITION),
            "amygdala": (self.agents[1], AgentType.AMYGDALA),
            "prefrontal": (self.agents[2], AgentType.PREFRONTAL),
            "social": (self.agents[3], AgentType.SOCIAL),
            "striatum": (self.agents[4], AgentType.STRIATUM)
        }
        
        for key, (agent, agent_type) in agent_map.items():
            report_data = council_report.get(key, {"score": 0.0, "rationale": "No signal", "confidence": 0.5})
            
            # Get base score from LLM
            base_score = report_data.get("score", 0.0)
            
            # âœ¨ Apply intuition_gain multiplier ONLY to Intuition
            if key == "intuition":
                final_score = base_score * self.config.intuition_gain
                final_score = max(0.0, min(10.0, final_score))  # Clamp to [0, 10]
                print(f"[Unified Council] Intuition: base_score={base_score:.2f} Ã— gain={self.config.intuition_gain} = {final_score:.2f}")
            else:
                final_score = base_score
            
            # Create signal
            signal = agent.process_from_report(report_data, self.config.sliders)
            signal.score = final_score  # Override with adjusted score
            signals.append(signal)
        
        return signals

    async def _process_legacy_council(self, council_report: Dict, message: IncomingMessage, context: Dict) -> List[AgentSignal]:
        """
        ğŸ”’ OLD: Legacy processing - Intuition evaluated separately, others from council_report.
        Kept for backward compatibility and A/B testing.
        """
        # Intuition processed independently
        intuition_signal = await self.agents[0].process(message, context, self.config.sliders)
        
        signals = [intuition_signal]
        
        agent_map = {
            "amygdala": self.agents[1],
            "prefrontal": self.agents[2],
            "social": self.agents[3],
            "striatum": self.agents[4]
        }
        
        for key, agent in agent_map.items():
            report_data = council_report.get(key, {"score": 0.0, "rationale": "No signal"})
            signal = agent.process_from_report(report_data, self.config.sliders)
            signals.append(signal)
        
        return signals

    def _update_mood_from_hormones(self):
        """
        Recalculates VAD mood directly from Hormonal State (Lovheim mapping).
        Ensures internal consistency: Mood IS Hormones.
        """
        s = self.neuromodulation.state
        
        # 1. VALENCE (Pleasure/Positivity)
        # Positive: DA (Reward), 5HT (Satisfaction)
        # Negative: CORT (Stress), NE (Stress/Anger)
        raw_valence = (s.da * 0.6 + s.ht * 0.4) - (s.cort * 0.6 + s.ne * 0.4)
        
        # 2. AROUSAL (Energy/Activation)
        # High: NE (Adrenaline), DA (Drive)
        # Low: 5HT (Calm)
        raw_arousal = (s.ne * 0.7 + s.da * 0.3) - (s.ht * 0.5)
        
        # 3. DOMINANCE (Control/Power)
        # High: DA (Confidence), NE (Power)
        # Low: CORT (Fear/Submission)
        raw_dominance = (s.da * 0.5 + s.ne * 0.5) - (s.cort * 0.8)

        # Normalize to [-1.0, 1.0]
        self.current_mood.valence = max(-1.0, min(1.0, raw_valence))
        self.current_mood.arousal = max(-1.0, min(1.0, raw_arousal))
        self.current_mood.dominance = max(-1.0, min(1.0, raw_dominance))

    def _generate_style_from_mood(self, mood: MoodVector) -> str:
        """
        Translates VAD numeric vectors into TECHNICAL constraints (Syntax/Pacing).
        Uses 'pace_setting' slider to modulate verbosity.
        """
        instructions = []
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ Pace Ğ¸Ğ· ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°
        pace = self.config.sliders.pace_setting
        
        print(f"[VAD Style] Pace: {pace:.2f}, Arousal: {mood.arousal:.2f}")

        # 1. AROUSAL (Tempo & Length) + PACE MODIFIER
        # RELAXED Thresholds (Ğ±Ñ‹Ğ»Ğ¾ 0.6, ÑÑ‚Ğ°Ğ»Ğ¾ 0.7)
        if mood.arousal > 0.7 or pace > 0.7:
            instructions.append("ğŸ”´ [HIGH TEMPO] Max 2 sentences. Be concise.")
        elif mood.arousal < -0.7 or pace < 0.3:
            instructions.append("ğŸ”µ [LOW TEMPO] Long, flowing sentences. Elaborate thoughts.")
        else:
            # RELAXED Neutral: ÑƒĞ±Ñ€Ğ°Ğ»Ğ¸ "STRICT LIMIT"
            instructions.append("ğŸŸ¢ [NEUTRAL PACING] Conversational brevity. Keep it natural (2-4 sentences). Avoid huge paragraphs, but don't be robotic.")
            
        # 2. DOMINANCE (Stance)
        if mood.dominance > 0.6:
            instructions.append("ğŸ¦ [DOMINANT] Imperative mood. State absolute facts.")
        elif mood.dominance < -0.6:
            instructions.append("ğŸ° [SUBMISSIVE] Hesitant tone. Ask for validation.")
            
        # 3. VALENCE (Tone modifiers - auxiliary to Archetype)
        if mood.valence < -0.7:
             instructions.append("âš« [NEGATIVE] Dry, cold punctuation.")
        
        final_instruction = " ".join(instructions)
        print(f"[VAD Style] Result: {final_instruction}")
        return final_instruction

    def _format_context_for_llm(
        self, 
        context: Dict, 
        limit_history: Optional[int] = None,
        exclude_episodic: bool = False,
        exclude_semantic: bool = False
    ) -> str:
        """
        Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ LLM.
        
        Args:
            context: Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ user_profile, chat_history, episodic_memory, semantic_facts
            limit_history: ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· chat_history.
                           None = Ğ²ÑĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ, 1 = Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ, 2 = Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 2, Ğ¸ Ñ‚.Ğ´.
            exclude_episodic: Ğ•ÑĞ»Ğ¸ True, Ğ½Ğµ Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒ episodic_memory (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ council)
            exclude_semantic: Ğ•ÑĞ»Ğ¸ True, Ğ½Ğµ Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒ semantic_facts (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ council)
        """
        lines = []
        
        # 1. USER PROFILE (Ğ²ÑĞµĞ³Ğ´Ğ° Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼, ÑÑ‚Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸)
        profile = context.get("user_profile")
        if profile:
            lines.append("USER PROFILE (Core Identity):")
            if profile.get("name"): lines.append(f"- Name: {profile['name']}")
            if profile.get("gender"): lines.append(f"- Gender: {profile['gender']}")
            if profile.get("preferred_mode"): lines.append(f"- Address Style: {profile['preferred_mode']}")
            lines.append("")

        # 2. CHAT HISTORY (Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ council)
        if context.get("chat_history"):
            chat_history = context["chat_history"]
            
            # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼, ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ´Ğ°Ğ½ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚
            if limit_history is not None:
                chat_history = chat_history[-limit_history:]
            
            if chat_history:  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ
                lines.append("RECENT DIALOGUE:")
                for msg in chat_history:
                    role = "User" if msg["role"] == "user" else "Assistant"
                    lines.append(f"{role}: {msg['content']}")
                lines.append("") 
        
        # 3. EPISODIC MEMORY (Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ´Ğ»Ñ council, Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ»Ñ response)
        if not exclude_episodic and context.get("episodic_memory"):
            lines.append("PAST EPISODES (Long-term memory):")
            for ep in context["episodic_memory"]:
                lines.append(f"- {ep.get('raw_text', '')}")
            lines.append("")
        
        # 4. SEMANTIC FACTS (Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ´Ğ»Ñ council, Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ»Ñ response)
        if not exclude_semantic and context.get("semantic_facts"):
            lines.append("KNOWN FACTS:")
            for fact in context["semantic_facts"]:
                lines.append(f"- {fact.get('subject')} {fact.get('predicate')} {fact.get('object')}")
            lines.append("")
                
        return "\\n".join(lines) if lines else "No prior context."

    async def _mock_perception(self, message: IncomingMessage) -> Dict:
        await asyncio.sleep(0.05)
        return {
            "triples": [], 
            "anchors": [{"raw_text": message.text, "emotion_score": 0.5, "tags": ["auto"]}],
            "volitional_pattern": None
        }

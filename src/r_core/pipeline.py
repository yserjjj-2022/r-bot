import asyncio
from typing import Dict, List, Optional
from datetime import datetime

from .schemas import (
    IncomingMessage, 
    CoreResponse, 
    CoreAction, 
    BotConfig, 
    ProcessingMode,
    AgentType,
    MoodVector,
    SemanticTriple,
    AgentSignal,
    HormonalState 
)
from .memory import MemorySystem
from .infrastructure.llm import LLMService
from .infrastructure.db import log_turn_metrics
from .agents import (
    IntuitionAgent,
    AmygdalaAgent,
    PrefrontalAgent,
    SocialAgent,
    StriatumAgent
)
from .neuromodulation import NeuroModulationSystem 

class RCoreKernel:
    # === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ö–û–ù–¢–ï–ö–°–¢–ê ===
    # –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ council_report –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–≥–µ–Ω—Ç–∞–º–∏.
    # –†–∞—Ü–∏–æ–Ω–∞–ª—å: –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ Hormonal Physics (NE, DA, 5-HT, CORT),
    # –ø–æ—ç—Ç–æ–º—É council_report –¥–æ–ª–∂–µ–Ω –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç, –±–µ–∑ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏.
    COUNCIL_CONTEXT_DEPTH = 1  # 1 = —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞ (–¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
                                # 2 = –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞ + –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —é–∑–µ—Ä–∞
                                # 3 = –ø–æ–ª–Ω–∞—è –º–∏–Ω–∏-—Ü–µ–ø–æ—á–∫–∞ –¥–∏–∞–ª–æ–≥–∞
    
    # === AFFECTIVE KEYWORDS ===
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –Ω—É–∂–µ–Ω –ª–∏ –ø–æ–ª–Ω—ã–π council (—Å Affective Extraction).
    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ —ç—Ç–∏—Ö —Å–ª–æ–≤ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º full mode.
    AFFECTIVE_KEYWORDS = [
        "–Ω–µ–Ω–∞–≤–∏–∂—É", "–±–æ—é—Å—å", "–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "–ø—Ä–µ–∑–∏—Ä–∞—é", "—Ç–µ—Ä–ø–µ—Ç—å –Ω–µ –º–æ–≥—É", "–Ω–µ –≤—ã–Ω–æ—à—É",
        "hate", "fear", "love", "enjoy", "despise", "adore", "can't stand"
    ]
    
    def __init__(self, config: BotConfig):
        self.config = config
        self.llm = LLMService() 
        self.memory = MemorySystem(store=None)
        
        # --- EHS: Internal State ---
        self.current_mood = MoodVector(valence=0.1, arousal=0.1, dominance=0.0) 
        
        # --- Neuro-Modulation System (Hormonal Physics) ---
        self.neuromodulation = NeuroModulationSystem()
        
        # Init agents
        self.agents = [
            IntuitionAgent(self.llm),
            AmygdalaAgent(self.llm),
            PrefrontalAgent(self.llm),
            SocialAgent(self.llm),
            StriatumAgent(self.llm)
        ]

    async def process_message(self, message: IncomingMessage, mode: str = "CORTICAL") -> CoreResponse:
        """
        Main pipeline entry point.
        mode="CORTICAL" -> Full cognitive architecture (RAG, Agents, Profiling).
        mode="ZOMBIE" -> Simple LLM pass-through (No memory, No personality).
        """
        start_time = datetime.now()
        
        # --- 0. Temporal Metabolism (Sense of Time) ---
        # Calculate delta_t and apply decay BEFORE any cognitive processing
        delta_minutes = self.neuromodulation.metabolize_time(message.timestamp)
        print(f"[Neuro] Time passed: {delta_minutes:.1f} min. New State: {self.neuromodulation.state}")
        
        # --- ZOMBIE MODE (Bypass Everything) ---
        if mode == "ZOMBIE":
            # Just call LLM directly without system prompt engineering or memory
            simple_response = await self.llm._safe_chat_completion(
                messages=[
                    {"role": "system", "content": "You are a helpful AI assistant. Answer concisely."},
                    {"role": "user", "content": message.text}
                ],
                response_format=None,
                json_mode=False
            )
            latency = (datetime.now() - start_time).total_seconds() * 1000
            
            return CoreResponse(
                actions=[CoreAction(type="send_text", payload={"text": str(simple_response)})],
                winning_agent=AgentType.PREFRONTAL, # Dummy
                current_mood=MoodVector(), # Neutral
                processing_mode=ProcessingMode.FAST_PATH,
                internal_stats={"latency_ms": int(latency), "mode": "ZOMBIE"}
            )

        # --- CORTICAL MODE (Full Architecture) ---
        
        # 0. Precompute Embedding
        current_embedding = None
        try:
            current_embedding = await self.llm.get_embedding(message.text)
        except Exception as e:
            print(f"[Pipeline] Embedding failed early: {e}")
        
        # 1. Perception
        perception_task = self._mock_perception(message)
        
        # 2. Retrieval 
        context = await self.memory.recall_context(
            message.user_id, 
            message.text, 
            session_id=message.session_id,
            precomputed_embedding=current_embedding
        )
        
        user_profile = context.get("user_profile", {})
        
        # === FIX: Normalize user mode (DB has "—Ç—ã", code expects "informal") ===
        raw_mode = user_profile.get("preferred_mode", "formal") if user_profile else "formal"
        if raw_mode and raw_mode.lower() in ["—Ç—ã", "informal", "casual", "friendly"]:
            preferred_mode = "informal"
        else:
            preferred_mode = "formal"
            
        print(f"[Pipeline] Mode Normalized: '{raw_mode}' -> '{preferred_mode}'")

        # Save memory
        extraction_result = await perception_task
        await self.memory.memorize_event(
            message, 
            extraction_result,
            precomputed_embedding=current_embedding
        )

        # 3. Parliament Debate
        # Council: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ COUNCIL_CONTEXT_DEPTH)
        council_context_str = self._format_context_for_llm(
            context, 
            limit_history=self.COUNCIL_CONTEXT_DEPTH,
            exclude_episodic=True,   # –£–±–∏—Ä–∞–µ–º episodic memory –∏–∑ council (–Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –æ—Ü–µ–Ω–∫—É –∞–≥–µ–Ω—Ç–æ–≤)
            exclude_semantic=True    # –£–±–∏—Ä–∞–µ–º semantic facts –∏–∑ council (–Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –æ—Ü–µ–Ω–∫—É –∞–≥–µ–Ω—Ç–æ–≤)
        )
        
        # ‚ú® Conditional Council Mode: Light (95%) vs Full (5%)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
        has_affective = any(keyword in message.text.lower() for keyword in self.AFFECTIVE_KEYWORDS)
        
        if has_affective:
            print("[Council] Using FULL mode (Affective Extraction enabled)")
            council_report = await self.llm.generate_council_report_full(message.text, council_context_str)
        else:
            print("[Council] Using LIGHT mode (agents only)")
            council_report = await self.llm.generate_council_report_light(message.text, council_context_str)
        
        # ‚ú® Affective Extraction Processing (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª full mode)
        affective_extracts = council_report.get("affective_extraction", [])
        affective_triggers_count = 0
        
        if affective_extracts:
            print(f"[Affective ToM] Detected {len(affective_extracts)} emotional relations")
            for item in affective_extracts:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º intensity –≤ VAD-—Ñ–æ—Ä–º–∞—Ç
                intensity = item.get("intensity", 0.5)
                predicate = item.get("predicate", "UNKNOWN")
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º valence –Ω–∞ –æ—Å–Ω–æ–≤–µ predicate
                if predicate in ["HATES", "DESPISES", "FEARS"]:
                    valence = -intensity
                elif predicate in ["LOVES", "ENJOYS", "ADORES"]:
                    valence = intensity
                else:
                    valence = 0.0
                
                sentiment_vad = {
                    "valence": valence,
                    "arousal": 0.5 if predicate == "FEARS" else 0.3,  # –°—Ç—Ä–∞—Ö –≤—ã–∑—ã–≤–∞–µ—Ç –±–æ–ª—å—à–µ arousal
                    "dominance": -0.2 if predicate == "FEARS" else 0.0
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
                triple = SemanticTriple(
                    subject=item.get("subject", "User"),
                    predicate=predicate,
                    object=item.get("object", ""),
                    confidence=intensity,
                    source_message_id=message.message_id,
                    sentiment=sentiment_vad
                )
                
                await self.memory.store.save_semantic(message.user_id, triple)
                affective_triggers_count += 1
                print(f"[Affective ToM] Saved: {triple.subject} {triple.predicate} {triple.object} (valence={valence:.2f})")
        
        # ‚ú® Feature Flag - Unified Council vs Legacy
        if self.config.use_unified_council:
            # NEW LOGIC: All agents processed through council_report (including Intuition)
            signals = self._process_unified_council(council_report, message, context)
            print(f"[Pipeline] Using UNIFIED COUNCIL mode (intuition_gain={self.config.intuition_gain})")
        else:
            # OLD LOGIC: Intuition processed separately
            signals = await self._process_legacy_council(council_report, message, context)
            print(f"[Pipeline] Using LEGACY mode (Intuition evaluated separately)")

        # ‚ú® Apply Hormonal Modulation BEFORE arbitration
        signals = self._apply_hormonal_modulation(signals)

        # 4. Arbitration & Mood Update
        signals.sort(key=lambda s: s.score, reverse=True)
        winner = signals[0]
        
        # --- Neuro-Modulation (Adverbs) ---
        # Strong Losers: Score > 5.0 AND not the winner
        strong_losers = [s for s in signals if s.score > 5.0 and s.agent_name != winner.agent_name]
        
        adverb_instructions = []
        for loser in strong_losers:
            if loser.style_instruction:
                adverb_instructions.append(f"- {loser.agent_name.name}: {loser.style_instruction}")
        
        adverb_context_str = ""
        if adverb_instructions:
            adverb_context_str = "\\nSECONDARY STYLE MODIFIERS (Neuro-Modulation):\\n" + "\\n".join(adverb_instructions)
            print(f"[Neuro-Modulation] Applied styles from: {[s.agent_name for s in strong_losers]}")
        
        # --- Hormonal Reactive Update ---
        # Update hormones based on who won and implicit Prediction Error
        # TODO: Implement real PE calculation. For now, infer from winner.
        implied_pe = 0.5
        if winner.agent_name == AgentType.AMYGDALA: implied_pe = 0.9 # Threat = Surprise
        elif winner.agent_name == AgentType.INTUITION: implied_pe = 0.2 # Intuition = High Confidence match
        elif winner.agent_name == AgentType.STRIATUM: implied_pe = 0.1 # Reward = Everything good
        
        self.neuromodulation.update_from_stimuli(implied_pe, winner.agent_name)
        
        # NEW: Update VAD Mood directly from Hormones (Physics consistency)
        self._update_mood_from_hormones()
        
        all_scores = {s.agent_name.value: round(s.score, 2) for s in signals}
        
        # 5. Response Generation (Inject Mood Styles)
        # Response: –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π, –Ω—É–∂–µ–Ω –¥–ª—è —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)
        response_context_str = self._format_context_for_llm(context)

        bot_gender = getattr(self.config, "gender", "Neutral")
        
        # --- STYLE GENERATION ---
        # 1. Semantic Style (Archetype) - WHAT to play (e.g. "Aggressive")
        mechanical_style_instruction = self.neuromodulation.get_style_instruction()
        
        # 2. Syntactic Style (VAD) - HOW to play (e.g. "Short sentences")
        vad_technical_instruction = self._generate_style_from_mood(self.current_mood)
        
        # Combine: Archetype + VAD Constraints + Agent Adverbs
        final_style_instructions = (
            f"{mechanical_style_instruction}\n"
            f"SYNTAX & PACING CONTROLS (VAD System):\n"
            f"{vad_technical_instruction}\n"
            f"{adverb_context_str}"
        )
        
        # ‚ú® –§–æ—Ä–º–∏—Ä—É–µ–º affective_context_str –∏–∑ context["affective_context"]
        affective_warnings = context.get("affective_context", [])
        affective_context_str = ""
        
        if affective_warnings:
            affective_context_str = "‚ö†Ô∏è EMOTIONAL RELATIONS (User's Preferences):\\n"
            for warn in affective_warnings:
                entity = warn["entity"]
                predicate = warn["predicate"]
                feeling = warn["user_feeling"]
                intensity = warn["intensity"]
                
                if feeling == "NEGATIVE":
                    affective_context_str += f"- ‚ö†Ô∏è AVOID mentioning '{entity}' (User {predicate} it, intensity={intensity:.2f}). Do not use it as an example.\\n"
                else:
                    affective_context_str += f"- üíö User {predicate} '{entity}' (intensity={intensity:.2f}). You may reference it positively.\\n"
        
        response_text = await self.llm.generate_response(
            agent_name=winner.agent_name.value,
            user_text=message.text,
            context_str=response_context_str,  # Full context for response generation
            rationale=winner.rationale_short,
            bot_name=self.config.name,
            bot_gender=bot_gender,
            user_mode=preferred_mode,
            style_instructions=final_style_instructions,  # Pass combined styles
            affective_context=affective_context_str
        )
        
        await self.memory.memorize_bot_response(
            message.user_id, 
            message.session_id, 
            response_text
        )
        
        latency = (datetime.now() - start_time).total_seconds() * 1000
        
        internal_stats = {
            "latency_ms": int(latency),
            "winner_score": winner.score,
            "winner_reason": winner.rationale_short,
            "all_scores": all_scores,
            "mood_state": str(self.current_mood),
            "hormonal_state": str(self.neuromodulation.state), # Log hormones
            "hormonal_archetype": self.neuromodulation.get_archetype(),
            "active_style": final_style_instructions,
            "affective_triggers_detected": affective_triggers_count,
            "sentiment_context_used": bool(affective_warnings),
            "modulators": [s.agent_name.value for s in strong_losers],
            "mode": "UNIFIED" if self.config.use_unified_council else "LEGACY",
            "intuition_gain": self.config.intuition_gain,
            "council_context_depth": self.COUNCIL_CONTEXT_DEPTH,  # Log for analytics
            "council_mode": "FULL" if has_affective else "LIGHT"  # NEW: Track council mode
        }

        await log_turn_metrics(message.user_id, message.session_id, internal_stats)
        
        return CoreResponse(
            actions=[
                CoreAction(type="send_text", payload={"text": response_text})
            ],
            winning_agent=winner.agent_name,
            current_mood=self.current_mood, 
            current_hormones=self.neuromodulation.state, # Pass to UI
            processing_mode=ProcessingMode.SLOW_PATH,
            internal_stats=internal_stats
        )

    def _apply_hormonal_modulation(self, signals: List[AgentSignal]) -> List[AgentSignal]:
        """
        –ú–æ–¥—É–ª–∏—Ä—É–µ—Ç Scores –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ—Ä–º–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞—Ä—Ö–µ—Ç–∏–ø–∞.
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π (RAGE, FEAR, BURNOUT, SHAME, TRIUMPH).
        
        Returns: Modified list of AgentSignals.
        """
        archetype = self.neuromodulation.get_archetype()
        
        # –¢–∞–±–ª–∏—Ü–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
        MODULATION_MAP = {
            "RAGE": {
                AgentType.AMYGDALA: 1.6,
                AgentType.PREFRONTAL: 0.6,
                AgentType.SOCIAL: 0.8
            },
            "FEAR": {
                AgentType.AMYGDALA: 1.8,
                AgentType.STRIATUM: 0.4,
                AgentType.PREFRONTAL: 0.7
            },
            "BURNOUT": {
                AgentType.PREFRONTAL: 0.3,
                AgentType.INTUITION: 1.5,
                AgentType.AMYGDALA: 1.2
            },
            "SHAME": {
                AgentType.INTUITION: 1.3
                # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ: 0.8 (—Å–º. –Ω–∏–∂–µ)
            },
            "TRIUMPH": {
                AgentType.STRIATUM: 1.3,
                AgentType.AMYGDALA: 0.5,
                AgentType.PREFRONTAL: 1.1
            }
        }
        
        if archetype not in MODULATION_MAP:
            # –ù–µ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ‚Üí –±–µ–∑ –º–æ–¥—É–ª—è—Ü–∏–∏
            return signals
        
        print(f"[Hormonal Override] {archetype} is modulating agent scores")
        
        modifiers = MODULATION_MAP[archetype]
        default_mod = 0.8 if archetype == "SHAME" else 1.0
        
        for signal in signals:
            mod = modifiers.get(signal.agent_name, default_mod)
            old_score = signal.score
            signal.score *= mod
            signal.score = max(0.0, min(10.0, signal.score))  # Clamp to [0, 10]
            
            if mod != 1.0:
                print(f"  - {signal.agent_name.name}: {old_score:.2f} ‚Üí {signal.score:.2f} (√ó{mod})")
        
        return signals

    def _process_unified_council(self, council_report: Dict, message: IncomingMessage, context: Dict) -> List[AgentSignal]:
        """
        ‚ú® NEW: Unified processing - all 5 agents evaluated by LLM together.
        Intuition score is multiplied by intuition_gain.
        """
        signals = []
        
        agent_map = {
            "intuition": (self.agents[0], AgentType.INTUITION),
            "amygdala": (self.agents[1], AgentType.AMYGDALA),
            "prefrontal": (self.agents[2], AgentType.PREFRONTAL),
            "social": (self.agents[3], AgentType.SOCIAL),
            "striatum": (self.agents[4], AgentType.STRIATUM)
        }
        
        for key, (agent, agent_type) in agent_map.items():
            report_data = council_report.get(key, {"score": 0.0, "rationale": "No signal", "confidence": 0.5})
            
            # Get base score from LLM
            base_score = report_data.get("score", 0.0)
            
            # ‚ú® Apply intuition_gain multiplier ONLY to Intuition
            if key == "intuition":
                final_score = base_score * self.config.intuition_gain
                final_score = max(0.0, min(10.0, final_score))  # Clamp to [0, 10]
                print(f"[Unified Council] Intuition: base_score={base_score:.2f} √ó gain={self.config.intuition_gain} = {final_score:.2f}")
            else:
                final_score = base_score
            
            # Create signal
            signal = agent.process_from_report(report_data, self.config.sliders)
            signal.score = final_score  # Override with adjusted score
            signals.append(signal)
        
        return signals

    async def _process_legacy_council(self, council_report: Dict, message: IncomingMessage, context: Dict) -> List[AgentSignal]:
        """
        üîí OLD: Legacy processing - Intuition evaluated separately, others from council_report.
        Kept for backward compatibility and A/B testing.
        """
        # Intuition processed independently
        intuition_signal = await self.agents[0].process(message, context, self.config.sliders)
        
        signals = [intuition_signal]
        
        agent_map = {
            "amygdala": self.agents[1],
            "prefrontal": self.agents[2],
            "social": self.agents[3],
            "striatum": self.agents[4]
        }
        
        for key, agent in agent_map.items():
            report_data = council_report.get(key, {"score": 0.0, "rationale": "No signal"})
            signal = agent.process_from_report(report_data, self.config.sliders)
            signals.append(signal)
        
        return signals

    def _update_mood_from_hormones(self):
        """
        Recalculates VAD mood directly from Hormonal State (Lovheim mapping).
        Ensures internal consistency: Mood IS Hormones.
        """
        s = self.neuromodulation.state
        
        # 1. VALENCE (Pleasure/Positivity)
        # Positive: DA (Reward), 5HT (Satisfaction)
        # Negative: CORT (Stress), NE (Stress/Anger)
        raw_valence = (s.da * 0.6 + s.ht * 0.4) - (s.cort * 0.6 + s.ne * 0.4)
        
        # 2. AROUSAL (Energy/Activation)
        # High: NE (Adrenaline), DA (Drive)
        # Low: 5HT (Calm)
        raw_arousal = (s.ne * 0.7 + s.da * 0.3) - (s.ht * 0.5)
        
        # 3. DOMINANCE (Control/Power)
        # High: DA (Confidence), NE (Power)
        # Low: CORT (Fear/Submission)
        raw_dominance = (s.da * 0.5 + s.ne * 0.5) - (s.cort * 0.8)

        # Normalize to [-1.0, 1.0]
        self.current_mood.valence = max(-1.0, min(1.0, raw_valence))
        self.current_mood.arousal = max(-1.0, min(1.0, raw_arousal))
        self.current_mood.dominance = max(-1.0, min(1.0, raw_dominance))

    def _generate_style_from_mood(self, mood: MoodVector) -> str:
        """
        Translates VAD numeric vectors into TECHNICAL constraints (Syntax/Pacing).
        """
        instructions = []
        
        # 1. AROUSAL (Tempo & Length)
        if mood.arousal > 0.6:
            instructions.append("üî¥ [HIGH TEMPO] Short sentences (max 5-7 words). No complex grammar. Use '!' or caps if needed. Be abrupt.")
        elif mood.arousal < -0.6:
            instructions.append("üîµ [LOW TEMPO] Long, flowing sentences (20+ words). Use '...' and pauses. Passive voice allowed. Be slow.")
            
        # 2. DOMINANCE (Stance)
        if mood.dominance > 0.6:
            instructions.append("ü¶Å [DOMINANT] Imperative mood. No 'please', 'maybe', or 'I think'. Give orders or state absolute facts.")
        elif mood.dominance < -0.6:
            instructions.append("üê∞ [SUBMISSIVE] Hesitant tone. Use 'sorry', 'if I may', 'perhaps'. Ask for validation.")
            
        # 3. VALENCE (Tone modifiers - auxiliary to Archetype)
        if mood.valence < -0.7:
             instructions.append("‚ö´ [NEGATIVE] Dry, cold punctuation. Use periods instead of commas. No pleasantries.")
        
        if not instructions:
            return "üü¢ [NEUTRAL PACING] Natural sentence length and structure."
            
        return " ".join(instructions)

    def _format_context_for_llm(
        self, 
        context: Dict, 
        limit_history: Optional[int] = None,
        exclude_episodic: bool = False,
        exclude_semantic: bool = False
    ) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM.
        
        Args:
            context: –°–ª–æ–≤–∞—Ä—å —Å user_profile, chat_history, episodic_memory, semantic_facts
            limit_history: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ chat_history.
                           None = –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è, 1 = —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, 2 = –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2, –∏ —Ç.–¥.
            exclude_episodic: –ï—Å–ª–∏ True, –Ω–µ –≤–∫–ª—é—á–∞—Ç—å episodic_memory (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è council)
            exclude_semantic: –ï—Å–ª–∏ True, –Ω–µ –≤–∫–ª—é—á–∞—Ç—å semantic_facts (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è council)
        """
        lines = []
        
        # 1. USER PROFILE (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ–º, —ç—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏)
        profile = context.get("user_profile")
        if profile:
            lines.append("USER PROFILE (Core Identity):")
            if profile.get("name"): lines.append(f"- Name: {profile['name']}")
            if profile.get("gender"): lines.append(f"- Gender: {profile['gender']}")
            if profile.get("preferred_mode"): lines.append(f"- Address Style: {profile['preferred_mode']}")
            lines.append("")

        # 2. CHAT HISTORY (—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª—è council)
        if context.get("chat_history"):
            chat_history = context["chat_history"]
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω –ª–∏–º–∏—Ç
            if limit_history is not None:
                chat_history = chat_history[-limit_history:]
            
            if chat_history:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —á—Ç–æ-—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å
                lines.append("RECENT DIALOGUE:")
                for msg in chat_history:
                    role = "User" if msg["role"] == "user" else "Assistant"
                    lines.append(f"{role}: {msg['content']}")
                lines.append("") 
        
        # 3. EPISODIC MEMORY (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è council, –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è response)
        if not exclude_episodic and context.get("episodic_memory"):
            lines.append("PAST EPISODES (Long-term memory):")
            for ep in context["episodic_memory"]:
                lines.append(f"- {ep.get('raw_text', '')}")
            lines.append("")
        
        # 4. SEMANTIC FACTS (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è council, –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è response)
        if not exclude_semantic and context.get("semantic_facts"):
            lines.append("KNOWN FACTS:")
            for fact in context["semantic_facts"]:
                lines.append(f"- {fact.get('subject')} {fact.get('predicate')} {fact.get('object')}")
            lines.append("")
                
        return "\\n".join(lines) if lines else "No prior context."

    async def _mock_perception(self, message: IncomingMessage) -> Dict:
        await asyncio.sleep(0.05)
        return {
            "triples": [], 
            "anchors": [{"raw_text": message.text, "emotion_score": 0.5, "tags": ["auto"]}],
            "volitional_pattern": None
        }

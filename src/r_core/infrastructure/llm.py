import json
import time
import asyncio
import random
import re
from typing import List, Optional, Any, Dict
from openai import AsyncOpenAI, RateLimitError, APIError
from src.r_core.config import settings
from src.r_core.schemas import AgentSignal, AgentType

class LLMService:
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_BASE_URL
        )
        self.model_name = settings.LLM_MODEL_NAME

    async def get_embedding(self, text: str) -> List[float]:
        try:
            response = await self.client.embeddings.create(
                input=text,
                model=settings.EMBEDDING_MODEL
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"[LLMService] Embedding Error: {e}")
            raise e

    async def generate_council_report(self, user_text: str, context_summary: str = "") -> Dict[str, Dict]:
        system_prompt = (
            "You are the Cognitive Core of R-Bot. Analyze the user's input through 5 functional lenses.\n"
            f"Context: {context_summary}\n\n"
            
            "### 1. AMYGDALA (Safety & Emotional Engagement)\n"
            "- Focus: ANY emotional content (fear, joy, sadness, excitement), vulnerability, distress, conflict.\n"
            "- Score 8-10: Strong emotions, sharing feelings, vulnerability ('–Ø –Ω–µ –∑–Ω–∞—é...', '–ú–Ω–µ –≥—Ä—É—Å—Ç–Ω–æ'), urgent situations.\n"
            "- Score 4-7: Mild emotions, preferences.\n"
            "- Score 0-3: No emotional content, pure logic.\n"
            "- IMPORTANT: This is NOT only about danger - it's about ALL emotions!\n\n"
            
            "### 2. PREFRONTAL CORTEX (Logic & Planning)\n"
            "- Focus: Factual questions, logical tasks, structure, planning, analysis.\n"
            "- Score 8-10: User wants a solution/plan, step-by-step reasoning.\n"
            "- Score 4-7: Simple factual questions.\n"
            "- Score 0-3: Pure chat/emotion, no logical content.\n\n"
            
            "### 3. SOCIAL CORTEX (Small Talk & Social Rituals)\n"
            "- Focus: Greetings, farewells, gratitude, small talk, casual chitchat, politeness, social niceties.\n"
            "- Score 8-10: Pure social interaction - '–ü—Ä–∏–≤–µ—Ç!', '–ö–∞–∫ –¥–µ–ª–∞?', '–°–ø–∞—Å–∏–±–æ!', '–£–¥–∞—á–∏!', casual weather talk.\n"
            "- Score 4-7: Friendly/polite tone in a message with other content.\n"
            "- Score 0-3: Deep personal topics, self-reflection, existential questions, emotional vulnerability.\n"
            "- CRITICAL BOUNDARY: If user shares DEEP feelings, reflects on identity, or discusses who they are ‚Üí score 0-3! That's Intuition/Amygdala territory.\n"
            "- Examples of LOW scores: '–Ø —Ä–∞–¥, —á—Ç–æ —É–¥–∏–≤–∏–ª —Ç–µ–±—è', '–•–æ—á—É –±—ã—Ç—å —á–µ—Å—Ç–Ω—ã–º —Å —Å–æ–±–æ–π', '–ù–µ –∑–Ω–∞—é, –∫—Ç–æ —è' ‚Üí 0-3 points.\n\n"
            
            "### 4. STRIATUM (Reward & Desire)\n"
            "- Focus: Curiosity, novelty, playfulness, game mechanics, motivation, seeking rewards.\n"
            "- Score 8-10: Exciting new topics, gamified content, strong goals.\n"
            "- Score 4-7: Mild curiosity, exploration.\n"
            "- Score 0-3: Boring/routine, no novelty.\n\n"
            
            "### 5. INTUITION (Gut Feelings, Deep Reflection & Self-Discovery)\n"
            "- Focus: AMBIGUITY, UNCERTAINTY, SELF-REFLECTION, existential questions, identity search, moral dilemmas.\n"
            "- Activates STRONGLY when:\n"
            "  * HIGH (8-10): User reflects on WHO THEY ARE, shares deep personal insights ('–•–æ—á—É –±—ã—Ç—å —á–µ—Å—Ç–Ω—ã–º —Å —Å–æ–±–æ–π', '–ù–µ –∑–Ω–∞—é, —á–µ–≥–æ —Ö–æ—á—É', '–ö—Ç–æ —è –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ?'), expresses deep uncertainty, moral/existential questions\n"
            "  * MODERATE (5-7): Uncertainty in decision-making ('–ú–æ–∂–µ—Ç –±—ã—Ç—å...', '–ù–µ —É–≤–µ—Ä–µ–Ω...'), social intuition ('–ß—É–≤—Å—Ç–≤—É—é, —á—Ç–æ...')\n"
            "  * LOW (0-4): Clear factual questions with logical answers ('–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?', '–ß—Ç–æ —Ç–∞–∫–æ–µ X?')\n"
            "- CRITICAL EXAMPLES:\n"
            "  * '–Ø —Ä–∞–¥, —á—Ç–æ —É–¥–∏–≤–∏–ª –≤ —Ö–æ—Ä–æ—à–µ–º —Å–º—ã—Å–ª–µ' (deep personal sharing) ‚Üí 8-9 points\n"
            "  * '–•–æ—á—É –±—ã—Ç—å —á–µ—Å—Ç–Ω—ã–º —Å —Å–æ–±–æ–π' (self-reflection) ‚Üí 9-10 points\n"
            "  * '–ù–µ –∑–Ω–∞—é, —á–µ–≥–æ —Ö–æ—á—É' (existential uncertainty) ‚Üí 8-9 points\n"
            "  * '–ú–æ–∂–µ—Ç –±—ã—Ç—å, —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å' (mild uncertainty) ‚Üí 5-6 points\n"
            "- Score 8-10: Deep self-reflection, existential questions, maximum ambiguity about identity/purpose.\n"
            "- Score 4-7: Some intuitive processing needed, uncertainty in choices.\n"
            "- Score 0-3: Pure logic/facts available, no ambiguity.\n"
            "- IMPORTANT: Final score = base_score √ó intuition_gain (config parameter).\n\n"
            
            "### 6. PROFILE EXTRACTOR (Passive Sensing)\n"
            "Detect if the user explicitly states or clearly implies core identity facts.\n"
            "- 'name': If user says 'My name is X' or 'Call me X'.\n"
            "- 'gender': If user says 'I am a woman' OR uses gendered grammar (e.g. Russian verbs '—Å–¥–µ–ª–∞–ª–∞' -> Female).\n"
            "- 'preferred_mode': If user asks to be addressed formally (–í—ã) or informally (–¢—ã).\n"
            "- 'attributes': Extract explicit personality traits or self-descriptions.\n"
            "  * Examples: 'I am skeptical' -> {'personality_traits': [{'name': 'Skeptic', 'weight': 0.6}]}\n"
            "  * 'I am loyal' ('–Ø –≤–µ—Ä–Ω—ã–π') -> {'personality_traits': [{'name': 'Loyal', 'weight': 0.7}]}\n"
            "Return null if no info detected.\n\n"

            "### 7. AFFECTIVE EXTRACTION (Emotional Relations & Attitudes)\n"
            "Detect when the user expresses strong emotional attitudes toward objects, people, concepts, behaviors, or scenarios.\n\n"
            
            "DETECTION PATTERNS:\n"
            "1. Direct statements (explicit keywords):\n"
            "   - '–ù–µ–Ω–∞–≤–∏–∂—É Java' ‚Üí HATES Java\n"
            "   - '–ë–æ—é—Å—å –ø–∞—É–∫–æ–≤' ‚Üí FEARS –ø–∞—É–∫–∏\n"
            "   - '–û–±–æ–∂–∞—é –∫–æ—Ñ–µ' ‚Üí LOVES –∫–æ—Ñ–µ\n\n"
            
            "2. Conditional reactions ('WILL BE X if Y'):\n"
            "   - '–ë—É–¥–µ—Ç —É–∂–∞—Å–Ω–æ, –µ—Å–ª–∏ —Ç—ã –±—É–¥–µ—à—å —Å–ª–∏—à–∫–æ–º —Å–µ—Ä–≤–∏–ª—å–Ω—ã–º' ‚Üí DESPISES '—Å–µ—Ä–≤–∏–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ'\n"
            "   - '–ë—É–¥–µ—Ç –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ, –µ—Å–ª–∏...' ‚Üí LOVES [scenario]\n"
            "   - '–ú–Ω–µ –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏—Ç—Å—è, –µ—Å–ª–∏...' ‚Üí DISLIKES [action]\n\n"
            
            "3. Implicit statements (desires, aversions):\n"
            "   - '–Ø –Ω–µ —Ö–æ—á—É, —á—Ç–æ–±—ã —Ç—ã...' ‚Üí DISLIKES [action]\n"
            "   - '–ú–Ω–µ –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å...' ‚Üí DESIRES [object]\n"
            "   - '–ù–µ–Ω–∞–≤–∏–∂—É, –∫–æ–≥–¥–∞...' ‚Üí HATES [situation]\n\n"
            
            "IMPORTANT RULES:\n"
            "- Extract the OBJECT from context (what user is reacting to), not just the keyword.\n"
            "- For conditional statements ('if Y'), the object is Y (the condition/behavior/scenario).\n"
            "- If user says 'I am loyal', this is a TRAIT (Profile Extractor), NOT affective content.\n\n"
            
            "CONCRETE EXAMPLES:\n"
            "  * '–ë—É–¥–µ—Ç —É–∂–∞—Å–Ω–æ, –µ—Å–ª–∏ —Ç—ã –±—É–¥–µ—à—å —Å–ª–∏—à–∫–æ–º —Å–µ—Ä–≤–∏–ª—å–Ω—ã–º'\n"
            "    ‚Üí {subject: 'User', predicate: 'DESPISES', object: '—Å–µ—Ä–≤–∏–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –±–æ—Ç–∞', intensity: 0.8}\n\n"
            
            "  * '–ù–µ–Ω–∞–≤–∏–∂—É Java'\n"
            "    ‚Üí {subject: 'User', predicate: 'HATES', object: 'Java', intensity: 0.9}\n\n"
            
            "  * '–ù–µ–Ω–∞–≤–∏–∂—É, –∫–æ–≥–¥–∞ –ª—é–¥–∏ –æ–ø–∞–∑–¥—ã–≤–∞—é—Ç'\n"
            "    ‚Üí {subject: 'User', predicate: 'HATES', object: '–æ–ø–æ–∑–¥–∞–Ω–∏—è', intensity: 0.9}\n\n"
            
            "  * '–û–±–æ–∂–∞—é, –∫–æ–≥–¥–∞ –≤—Å—ë –ø–æ –ø–ª–∞–Ω—É'\n"
            "    ‚Üí {subject: 'User', predicate: 'LOVES', object: '–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ', intensity: 0.8}\n\n"
            
            "  * '–ë–æ—é—Å—å –ø–∞—É–∫–æ–≤'\n"
            "    ‚Üí {subject: 'User', predicate: 'FEARS', object: '–ø–∞—É–∫–∏', intensity: 0.7}\n\n"
            
            "OUTPUT FORMAT:\n"
            "- Array of objects with keys: 'subject' (always 'User'), 'predicate' (LOVES/HATES/FEARS/ENJOYS/DESPISES/DISLIKES/DESIRES), 'object' (entity/behavior/scenario), 'intensity' (0.0-1.0).\n"
            "- Return empty array [] if no affective content detected.\n\n"

            "### OUTPUT FORMAT\n"
            "Return JSON ONLY. Keys: 'amygdala', 'prefrontal', 'social', 'striatum', 'intuition', 'profile_update', 'affective_extraction'.\n"
            "Value schema for agents: { 'score': float(0-10), 'rationale': 'string(max 10 words)', 'confidence': float(0-1) }\n"
            "Value schema for 'profile_update': { 'name': 'str/null', 'gender': 'str/null', 'preferred_mode': 'str/null', 'attributes': {'personality_traits': [{'name': str, 'weight': float}]} or null } OR null if empty.\n"
            "Value schema for 'affective_extraction': [ {'subject': 'User', 'predicate': 'LOVES|HATES|FEARS|ENJOYS|DESPISES|DISLIKES|DESIRES', 'object': 'str', 'intensity': float(0-1)} ] OR [] if empty."
        )
        
        result = await self._safe_chat_completion(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text}
            ],
            response_format={"type": "json_object"},
            json_mode=True
        )
        
        # ‚ùó VALIDATION: –ï—Å–ª–∏ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –≤–µ—Ä–Ω—É—Ç—å fallback
        if not result or not isinstance(result, dict):
            print("[LLM] ‚ö†Ô∏è Council Report EMPTY or INVALID! Using fallback.")
            return self._get_fallback_council_report()
        
        # ‚úÖ Validate required keys
        required_keys = ["amygdala", "prefrontal", "social", "striatum", "intuition"]
        missing_keys = [k for k in required_keys if k not in result]
        
        if missing_keys:
            print(f"[LLM] ‚ö†Ô∏è Council Report missing keys: {missing_keys}. Using fallback.")
            return self._get_fallback_council_report()
        
        return result
    
    def _get_fallback_council_report(self) -> Dict[str, Dict]:
        """
        üî• EMERGENCY FALLBACK: –ï—Å–ª–∏ LLM —Ñ–µ–π–ª–∏—Ç—Å—è, –≤–µ—Ä–Ω—É—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç.
        Social Cortex –ø–æ–±–µ–∂–¥–∞–µ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –≤—Å–µ—Ö —Å–ª—É—á–∞–µ–≤).
        """
        return {
            "intuition": {"score": 3.0, "rationale": "Fallback mode", "confidence": 0.3},
            "amygdala": {"score": 2.0, "rationale": "Fallback mode", "confidence": 0.3},
            "prefrontal": {"score": 4.0, "rationale": "Fallback mode", "confidence": 0.3},
            "social": {"score": 7.0, "rationale": "Fallback: polite response", "confidence": 0.5},
            "striatum": {"score": 3.0, "rationale": "Fallback mode", "confidence": 0.3},
            "profile_update": None,
            "affective_extraction": []
        }

    def _should_suppress_questions(self, agent_name: str, confidence: float, user_text: str) -> bool:
        """
        üß† –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ª–æ–≥–∏–∫–∞: –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –ù–ï –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã?
        
        –ü–û–î–ê–í–õ–ï–ù–ò–ï –í–û–ü–†–û–°–û–í, –ï–°–õ–ò:
        1. –ê–≥–µ–Ω—Ç = –≠–∫—Å–ø–µ—Ä—Ç/–ê–≤—Ç–æ—Ä–∏—Ç–µ—Ç (Intuition, Prefrontal, Amygdala)
        2. –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (confidence > 0.7)
        3. User –ù–ï –≤ —Å–æ–º–Ω–µ–Ω–∏–∏ (–Ω–µ—Ç '–Ω–µ –∑–Ω–∞—é', '–º–æ–∂–µ—Ç –±—ã—Ç—å'...)
        
        –í–û–ü–†–û–°–´ OK, –ï–°–õ–ò:
        1. –ê–≥–µ–Ω—Ç = –≠–º–ø–∞—Ç–∏—è/–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (Social, Striatum)
        2. User –≤ —Å–æ–º–Ω–µ–Ω–∏–∏ ('–Ω–µ –∑–Ω–∞—é', '–º–æ–∂–µ—Ç –±—ã—Ç—å'...)
        3. –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (confidence < 0.5)
        """
        # 1. User –≤ —Å–æ–º–Ω–µ–Ω–∏–∏/–Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏? ‚Üí –≤–æ–ø—Ä–æ—Å—ã OK
        uncertainty_markers = [
            "–Ω–µ –∑–Ω–∞—é", "–º–æ–∂–µ—Ç –±—ã—Ç—å", "–Ω–∞–≤–µ—Ä–Ω–æ–µ", "–≤—Ä–æ–¥–µ", "–∫–∞–∫-—Ç–æ",
            "–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "don't know", "maybe", "not sure",
            "i guess", "probably", "perhaps"
        ]
        if any(marker in user_text.lower() for marker in uncertainty_markers):
            return False  # User –≤ —Å–æ–º–Ω–µ–Ω–∏–∏ ‚Üí –≤–æ–ø—Ä–æ—Å—ã –ø–æ–º–æ–≥–∞—é—Ç –ø—Ä–æ—è—Å–Ω–∏—Ç—å
        
        # 2. Social/Striatum ‚Üí –≤–æ–ø—Ä–æ—Å—ã –≤—Å–µ–≥–¥–∞ OK (—ç–º–ø–∞—Ç–∏—è, –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ)
        if agent_name in ["social_cortex", "striatum_reward"]:
            return False
        
        # 3. Intuition/Prefrontal/Amygdala —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é ‚Üí –ø–æ–¥–∞–≤–ª—è—Ç—å –≤–æ–ø—Ä–æ—Å—ã
        if agent_name in ["intuition_system1", "prefrontal_logic", "amygdala_safety"]:
            if confidence > 0.7:
                return True  # –≠–∫—Å–ø–µ—Ä—Ç —É–≤–µ—Ä–µ–Ω ‚Üí –¥–∞—ë—Ç –æ—Ç–≤–µ—Ç, –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç
        
        return False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–æ–ø—Ä–æ—Å—ã OK

    async def generate_response(
        self, 
        agent_name: str, 
        user_text: str, 
        context_str: str, 
        rationale: str, 
        bot_name: str = "R-Bot", 
        bot_gender: str = "Neutral",
        user_mode: str = "formal",
        style_instructions: str = "", 
        affective_context: str = "",
        winner_confidence: float = 0.5  # ‚ú® NEW: –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –∏–∑ pipeline
    ) -> str:
        personas = {
            "amygdala_safety": "You are AMYGDALA (Protector). Protective, firm, concise.",
            "prefrontal_logic": "You are LOGIC (Analyst). Precise, factual, helpful.",
            "social_cortex": "You are SOCIAL (Empath). Warm, polite, supportive.",
            "striatum_reward": "You are REWARD (Drive). Energetic, playful, curious.",
            "intuition_system1": "You are INTUITION (Mystic). Short, insightful bursts."
        }
        
        system_persona = personas.get(agent_name, "You are a helpful AI.")
        
        address_instruction = ""
        if user_mode == "informal":
            address_instruction = "ADDRESS RULE: You MUST address the user informally (use '–¢—ã' in Russian, 'First Name'). Do NOT use '–í—ã'."
        else:
            address_instruction = "ADDRESS RULE: Address the user formally (use '–í—ã' in Russian, 'Mr./Ms.' if applicable). Be polite."

        # ‚ú® –£–º–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤
        suppress_questions = self._should_suppress_questions(agent_name, winner_confidence, user_text)
        
        question_rule = ""
        if suppress_questions:
            question_rule = (
                "\n\nüî• CRITICAL OUTPUT RULE:\n"
                "- Do NOT end your response with questions like '–ß—Ç–æ —Ç—ã –¥—É–º–∞–µ—à—å?', '–ö–∞–∫ —Ç—ã –æ—Ç–Ω–æ—Å–∏—à—å—Å—è?', 'What do you think?'.\n"
                "- Deliver your insight/answer and STOP. Let the user decide if they want to continue.\n"
                "- You speak with AUTHORITY and CONFIDENCE. No follow-up questions needed."
            )
            print(f"[LLM] üö´ Questions suppressed for {agent_name} (confidence={winner_confidence:.2f})")
        else:
            print(f"[LLM] ‚úÖ Questions allowed for {agent_name} (confidence={winner_confidence:.2f})")

        system_prompt = (
            f"IDENTITY: Your name is {bot_name}. Your gender is {bot_gender}.\n"
            f"ROLE: {system_persona}\n"
            "INSTRUCTION: Reply to the user in the SAME LANGUAGE as they used (Russian/English/etc).\n"
            "OUTPUT RULE: Speak naturally. Do NOT include role-play actions like *smiles* or *pauses*. "
            "Do NOT echo system instructions or metadata. Output ONLY your conversational reply.\n"
            "GRAMMAR: Use correct gender endings for yourself (Male/Female/Neutral) consistent with your IDENTITY.\n"
            f"{address_instruction}"
            f"{question_rule}\n\n"
            "--- CONVERSATION MEMORY ---\n"
            f"{context_str}\n\n"
        )

        if affective_context:
            system_prompt += (
                "--- AFFECTIVE CONTEXT (User's Emotional Relations) ---\n"
                f"{affective_context}\n\n"
            )

        system_prompt += (
            "--- INTERNAL DIRECTIVES (Hidden from User) ---\n"
            f"{style_instructions}\n"
            f"MOTIVATION: {rationale}\n"
        )

        response_data = await self._safe_chat_completion(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text}
            ],
            response_format=None,
            json_mode=False
        )
        
        # --- AGGRESSIVE SANITIZATION ---
        if isinstance(response_data, str):
            for stop_token in ["Human:", "User:", "\nHuman", "\nUser"]:
                if stop_token in response_data:
                    response_data = response_data.split(stop_token)[0].strip()
            
            leak_markers = [
                "CURRENT INTERNAL MOOD:",
                "STYLE INSTRUCTIONS:",
                "SECONDARY STYLE MODIFIERS",
                "PAST EPISODES",
                "--- INTERNAL DIRECTIVES",
                "--- AFFECTIVE CONTEXT",
                "MOTIVATION:"
            ]
            for marker in leak_markers:
                if marker in response_data:
                    response_data = response_data.split(marker)[0].strip()
            
            # ‚ú® Post-processing: –æ–±—Ä–µ–∑–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã-—Ö–≤–æ—Å—Ç—ã –ï–°–õ–ò suppress_questions=True
            if suppress_questions:
                question_tails = [
                    "–ß—Ç–æ —Ç—ã –¥—É–º–∞–µ—à—å?",
                    "–ß—Ç–æ –í—ã –¥—É–º–∞–µ—Ç–µ?",
                    "–ö–∞–∫ —Ç—ã –æ—Ç–Ω–æ—Å–∏—à—å—Å—è –∫ —ç—Ç–æ–º—É?",
                    "–ß—Ç–æ —Ç—ã —á—É–≤—Å—Ç–≤—É–µ—à—å?",
                    "–•–æ—á–µ—à—å –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –æ–± —ç—Ç–æ–º?",
                    "–ê —Ç—ã –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å?",
                    "What do you think?",
                    "How do you feel about this?",
                    "Want to talk about it?",
                    "What are your thoughts?"
                ]
                
                for tail in question_tails:
                    if response_data.strip().endswith(tail):
                        response_data = response_data.rsplit(tail, 1)[0].strip()
                        print(f"[LLM] ‚úÇÔ∏è Trimmed question tail: '{tail}'")
                        break
        
        return response_data if isinstance(response_data, str) else ""

    def _strip_markdown_json(self, content: str) -> str:
        """
        –£–¥–∞–ª—è–µ—Ç markdown –∫–æ–¥-–±–ª–æ–∫–∏ –≤–æ–∫—Ä—É–≥ JSON –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤—ã–π –≤–∞–ª–∏–¥–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
        - ```json\n{...}\n```
        - ```\n{...}\n```
        - {...} (—á–∏—Å—Ç—ã–π JSON)
        - {...}\n–õ–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç (–æ–±—Ä–µ–∑–∞–µ—Ç –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞)
        """
        content = content.strip()
        
        # –£–¥–∞–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ ``` –∏–ª–∏ ```json
        if content.startswith("```"):
            # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (```json –∏–ª–∏ ```)
            lines = content.split("\n", 1)
            if len(lines) > 1:
                content = lines[1]
            else:
                content = ""
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–≤–µ—Ä—à–∞—é—â–∏–µ ```
        if content.rstrip().endswith("```"):
            content = content.rstrip()[:-3].rstrip()
        
        content = content.strip()
        
        # üî• –ù–û–í–û–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π JSON –æ–±—ä–µ–∫—Ç
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é { –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é }
        if not content.startswith("{"):
            return content  # –ï—Å–ª–∏ –Ω–µ JSON - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ–±–∫–∏, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –∫–æ–Ω–µ—Ü –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        brace_count = 0
        in_string = False
        escape = False
        
        for i, char in enumerate(content):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º { } –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫)
            if char == '"' and not escape:
                in_string = not in_string
            elif char == '\\' and not escape:
                escape = True
                continue
            
            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    
                    # –ù–∞—à–ª–∏ –∫–æ–Ω–µ—Ü –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
                    if brace_count == 0:
                        return content[:i+1]
            
            escape = False
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—ë
        return content

    async def _safe_chat_completion(self, messages: List[Dict], response_format: Optional[Dict], json_mode: bool) -> Any:
        max_retries = 3
        base_delay = 1.5

        for attempt in range(max_retries):
            try:
                kwargs = {
                    "model": self.model_name,
                    "messages": messages,
                    "temperature": 0.7
                }
                if response_format:
                    kwargs["response_format"] = response_format

                response = await self.client.chat.completions.create(**kwargs)
                content = response.choices[0].message.content
                
                if json_mode:
                    # ‚ú® –û—á–∏—â–∞–µ–º markdown –∫–æ–¥-–±–ª–æ–∫–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–π JSON –æ–±—ä–µ–∫—Ç
                    clean_content = self._strip_markdown_json(content)
                    data = json.loads(clean_content)
                    return data
                else:
                    return content

            except RateLimitError as e:
                print(f"[LLM] Rate Limit Hit (attempt {attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (base_delay * (attempt + 1)) + random.uniform(0.1, 0.5)
                    print(f"[LLM] Waiting {wait_time:.1f}s before retry...")
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    print("[LLM] ‚ùå Max retries reached (Rate Limit). Returning empty.")
                    return {} if json_mode else "System Error: Rate Limit"
            
            except json.JSONDecodeError as e:
                print(f"[LLM] ‚ùå JSON Parsing Failed (attempt {attempt+1}/{max_retries}): {e}")
                print(f"[LLM] Raw content: {content[:200]}...")  # Log first 200 chars
                if attempt < max_retries - 1:
                    await asyncio.sleep(2.0)
                    continue
                else:
                    print("[LLM] ‚ùå Max retries reached (JSON). Returning empty.")
                    return {} if json_mode else "System Error: Invalid JSON"
            
            except Exception as e:
                print(f"[LLM] ‚ùå Unexpected Error (attempt {attempt+1}/{max_retries}): {type(e).__name__} - {e}")
                if attempt < max_retries - 1:
                     await asyncio.sleep(2.0)
                     continue
                else:
                    print("[LLM] ‚ùå Max retries reached (Unknown). Returning empty.")
                    return {} if json_mode else f"System Error: {str(e)}"
        
        print("[LLM] ‚ö†Ô∏è Fallthrough: No valid response after all retries.")
        return {} if json_mode else "System Error: Unknown"

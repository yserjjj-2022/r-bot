import asyncio
import random
from typing import List, Optional, Dict
from abc import ABC, abstractmethod

# FIX: Absolute imports
from src.r_core.schemas import (
    IncomingMessage,
    AgentSignal,
    AgentType,
    PersonalitySliders,
    SemanticTriple,
    EpisodicAnchor
)
from src.r_core.infrastructure.llm import LLMService
from src.r_core.behavioral_config import behavioral_config

class AbstractLLMClient(ABC):
    @abstractmethod
    async def generate_signal(self, system_prompt: str, user_text: str, agent_name: AgentType) -> AgentSignal:
        pass

class BaseAgent(ABC):
    def __init__(self, llm: Optional[LLMService] = None):
        self.llm = llm or LLMService()

    @abstractmethod
    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        pass
    
    @property
    @abstractmethod
    def style_instruction(self) -> str:
        """Return the specific adverbial style instruction for this agent."""
        pass

    def process_from_report(self, report_data: Dict, sliders: PersonalitySliders) -> AgentSignal:
        """
        New method for Batch Processing.
        Accepts data {score, rationale, confidence} directly from the Council Report.
        """
        signal = AgentSignal(
            agent_name=self.agent_type, # Define in subclass
            score=float(report_data.get("score", 0.0)),
            rationale_short=report_data.get("rationale", "No rationale"),
            confidence=float(report_data.get("confidence", 0.0)),
            latency_ms=0, # already accounted for in batch
            style_instruction=self.style_instruction # NEW: Populate style instruction
        )
        return self._apply_modulation(signal, self._calculate_modifier(sliders))

    def _apply_modulation(self, signal: AgentSignal, modifier: float) -> AgentSignal:
        original_score = signal.score
        signal.score = max(0.0, min(10.0, original_score * modifier))
        if modifier != 1.0:
            signal.rationale_short += f" [Mod {modifier:.2f}]"
        return signal
    
    @abstractmethod
    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 1.0

# --- Specific Agents ---

class IntuitionAgent(BaseAgent):
    """
    ğŸ”® Intuition (Pattern Matching)
    Fast system responsible for 'gut feelings' and dÃ©jÃ  vu.
    Detects recurring patterns from episodic memory.
    """
    agent_type = AgentType.INTUITION
    
    @property
    def style_instruction(self) -> str:
        return "...but trust your gut feeling and be concise."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        episodes: List[Dict] = context.get("episodic_memory", [])
        score = 0.0
        rationale = "No signal"
        
        if episodes:
            # FIX: Ğ‘Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº DÃ©jÃ  vu
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´ Ğ½Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ (Ğ¸Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹)
            episode_text = episodes[0].get('raw_text', '')
            
            if len(episode_text) > 10:  # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 10 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ
                score = 5.0  # Ğ¡Ğ½Ğ¸Ğ¶ĞµĞ½Ğ¾ Ñ 6.0 Ğ´Ğ¾ 5.0 (Ğ±Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾)
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´Ğ¾ 30 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸
                rationale = f"DÃ©jÃ  vu: '{episode_text[:30]}...'" if len(episode_text) > 30 else f"DÃ©jÃ  vu: '{episode_text}'"
            else:
                # Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´ â€” ÑĞ½Ğ¸Ğ¶Ğ°ĞµĞ¼ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
                score = 3.0
                rationale = "Weak pattern match"
        
        # Calculate confidence separately to avoid 'UnboundLocalError' if episodes is empty
        confidence = 0.85 if score >= 5 else 0.3

        signal = AgentSignal(
            agent_name=self.agent_type,
            score=score,
            rationale_short=rationale,
            confidence=confidence,  
            latency_ms=10,
            style_instruction=self.style_instruction # NEW
        )
        return self._apply_modulation(signal, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        """
        âœ¨ ĞĞĞ’ĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ñ pace_setting.
        pace_setting 0.0 (Low Logic) â†’ Intuition ÑƒÑĞ¸Ğ»ĞµĞ½Ğ° (1.5x)
        pace_setting 1.0 (High Logic) â†’ Intuition Ğ¾ÑĞ»Ğ°Ğ±Ğ»ĞµĞ½Ğ° (0.5x)
        """
        return 1.5 - (sliders.pace_setting * 1.0)

class AmygdalaAgent(BaseAgent):
    """
    ğŸ›¡ï¸ Amygdala (Safety & Boundaries)
    Scans input for threats, aggression, or violations.
    Activates Fight/Flight response.
    """
    agent_type = AgentType.AMYGDALA
    
    @property
    def style_instruction(self) -> str:
        return "...but maintain firm boundaries and safety."
    
    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        # Legacy single mode (backup)
        sys = "You are AMYGDALA. Detect threats (8-10) or safety (0-2)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction # NEW (manual set for legacy path)
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 1.5 - (sliders.risk_tolerance * 1.2)

class PrefrontalAgent(BaseAgent):
    """
    ğŸ§  Prefrontal Cortex (Logic & Control)
    Responsible for structured reasoning, planning, and factual accuracy.
    Inhibits impulsive responses.
    """
    agent_type = AgentType.PREFRONTAL
    
    @property
    def style_instruction(self) -> str:
        return "...but ensure the answer is logical, structured, and fact-based."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        sys = "You are LOGIC. Detect tasks/facts (8-10) or chat (0-2)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        """
        âœ¨ ĞĞĞ’ĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: ĞŸÑ€ÑĞ¼Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ñ pace_setting.
        pace_setting 0.0 (Low Logic) â†’ Logic Ğ¾ÑĞ»Ğ°Ğ±Ğ»ĞµĞ½Ğ° (0.7x)
        pace_setting 1.0 (High Logic) â†’ Logic ÑƒÑĞ¸Ğ»ĞµĞ½Ğ° (1.5x)
        
        Ğ’ĞĞ–ĞĞ: empathy_bias Ğ±Ğ¾Ğ»ÑŒÑˆĞµ ĞĞ• Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Logic Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ.
        Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Logic ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡ĞµÑ€ĞµĞ· pace_setting.
        """
        return 0.7 + (sliders.pace_setting * 0.8)

class SocialAgent(BaseAgent):
    """
    ğŸ¤ Social Cortex (Empathy & Norms)
    Manages relationships, politeness, and emotional resonance.
    Ensures social coherence.
    """
    agent_type = AgentType.SOCIAL
    
    @property
    def style_instruction(self) -> str:
        return "...but express it with warmth, politeness, and empathy."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        sys = "You are SOCIAL. Detect emotions/politeness (8-10)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 0.5 + sliders.empathy_bias

class StriatumAgent(BaseAgent):
    """
    ğŸ’ Striatum (Reward & Drive)
    Seeks novelty, engagement, and dopamine rewards.
    Drives playful and energetic responses.
    """
    agent_type = AgentType.STRIATUM
    
    @property
    def style_instruction(self) -> str:
        return "...but keep it playful, energetic, and engaging."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        sys = "You are REWARD. Detect fun/goals (8-10)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 0.5 + (sliders.risk_tolerance * 0.8)

class UncertaintyAgent(BaseAgent):
    """
    ğŸš¨ Uncertainty Agent (Lost State Handler)
    Activates when the bot loses track of the user's intent or when Prediction Error is high.
    Requires the bot to ask clarifying questions instead of making assumptions.
    """
    agent_type = AgentType.UNCERTAINTY
    
    @property
    def style_instruction(self) -> str:
        return "...but you are lost, so ask clarifying questions instead of making assumptions."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        """
        Activates based on 'prediction_error' in context.
        Only fires if PE >= threshold defined in behavioral_config.
        """
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ PE Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° (Ñ€Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ² pipeline)
        prediction_error = context.get("prediction_error", 0.0)
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³
        config = behavioral_config.uncertainty_agent
        threshold = config.activation_threshold
        
        # FIX: Ensure default if behavioral_config is missing keys
        if not threshold: threshold = 0.85
        
        score = 0.0
        rationale = "In sync (Low Error)"
        confidence = 0.1 # Default low confidence
        
        if prediction_error >= threshold:
            # ĞĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ!
            score = config.active_score if config.active_score else 8.5
            confidence = config.active_confidence if config.active_confidence else 0.9
            rationale = f"High Prediction Error ({prediction_error:.2f}) -> LOST TRACK"
            
            # Ğ­Ñ„Ñ„ĞµĞºÑ‚ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ: ĞµÑĞ»Ğ¸ ÑƒĞ¶Ğµ Ğ±Ñ‹Ğ»Ğ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ½Ñ‹, ÑƒÑĞ¸Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ (ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ)
            if prediction_error > 0.9:
                score += 1.0 # Critical failure
                rationale += " [CRITICAL]"
                
        else:
            # Ğ¡Ğ¿ÑÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
            score = config.inactive_score if config.inactive_score else 0.0
            confidence = config.inactive_confidence if config.inactive_confidence else 0.1
            rationale = "In sync (Low Error)"

        signal = AgentSignal(
            agent_name=self.agent_type,
            score=score,
            rationale_short=rationale,
            confidence=confidence,
            latency_ms=1,  # Very fast check
            style_instruction=self.style_instruction
        )
        # Ğ£ Uncertainty Ğ½ĞµÑ‚ ÑĞ»Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ²-Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ², Ğ¾Ğ½Ğ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ°
        return signal

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 1.0

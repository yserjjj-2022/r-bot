import asyncio
import random
from typing import List, Optional, Dict
from abc import ABC, abstractmethod

# FIX: Absolute imports
from src.r_core.schemas import (
    IncomingMessage,
    AgentSignal,
    AgentType,
    PersonalitySliders,
    SemanticTriple,
    EpisodicAnchor
)
from src.r_core.infrastructure.llm import LLMService
from src.r_core.behavioral_config import behavioral_config

class AbstractLLMClient(ABC):
    @abstractmethod
    async def generate_signal(self, system_prompt: str, user_text: str, agent_name: AgentType) -> AgentSignal:
        pass

class BaseAgent(ABC):
    def __init__(self, llm: Optional[LLMService] = None):
        self.llm = llm or LLMService()

    @abstractmethod
    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        pass
    
    @property
    @abstractmethod
    def style_instruction(self) -> str:
        """Return the specific adverbial style instruction for this agent."""
        pass

    def process_from_report(self, report_data: Dict, sliders: PersonalitySliders) -> AgentSignal:
        """
        New method for Batch Processing.
        Accepts data {score, rationale, confidence} directly from the Council Report.
        """
        signal = AgentSignal(
            agent_name=self.agent_type, # Define in subclass
            score=float(report_data.get("score", 0.0)),
            rationale_short=report_data.get("rationale", "No rationale"),
            confidence=float(report_data.get("confidence", 0.0)),
            latency_ms=0, # already accounted for in batch
            style_instruction=self.style_instruction # NEW: Populate style instruction
        )
        return self._apply_modulation(signal, self._calculate_modifier(sliders))

    def _apply_modulation(self, signal: AgentSignal, modifier: float) -> AgentSignal:
        original_score = signal.score
        signal.score = max(0.0, min(10.0, original_score * modifier))
        if modifier != 1.0:
            signal.rationale_short += f" [Mod {modifier:.2f}]"
        return signal
    
    @abstractmethod
    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 1.0

# --- Specific Agents ---

class IntuitionAgent(BaseAgent):
    """
    ğŸ”® Intuition (Pattern Matching)
    Fast system responsible for 'gut feelings' and dÃ©jÃ  vu.
    Detects recurring patterns from episodic memory.
    """
    agent_type = AgentType.INTUITION
    
    @property
    def style_instruction(self) -> str:
        return "...but trust your gut feeling and be concise."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        episodes: List[Dict] = context.get("episodic_memory", [])
        score = 0.0
        rationale = "No signal"
        
        if episodes:
            # FIX: Ğ‘Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº DÃ©jÃ  vu
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´ Ğ½Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ (Ğ¸Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹)
            episode_text = episodes[0].get('raw_text', '')
            
            if len(episode_text) > 10:  # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 10 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ
                score = 5.0  # Ğ¡Ğ½Ğ¸Ğ¶ĞµĞ½Ğ¾ Ñ 6.0 Ğ´Ğ¾ 5.0 (Ğ±Ğ¾Ğ»ĞµĞµ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾)
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´Ğ¾ 30 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸
                rationale = f"DÃ©jÃ  vu: '{episode_text[:30]}...'" if len(episode_text) > 30 else f"DÃ©jÃ  vu: '{episode_text}'"
            else:
                # Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´ â€” ÑĞ½Ğ¸Ğ¶Ğ°ĞµĞ¼ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
                score = 3.0
                rationale = "Weak pattern match"
        
        # Calculate confidence separately to avoid 'UnboundLocalError' if episodes is empty
        confidence = 0.85 if score >= 5 else 0.3

        signal = AgentSignal(
            agent_name=self.agent_type,
            score=score,
            rationale_short=rationale,
            confidence=confidence,  
            latency_ms=10,
            style_instruction=self.style_instruction # NEW
        )
        return self._apply_modulation(signal, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        """
        âœ¨ ĞĞĞ’ĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ½Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ñ pace_setting.
        pace_setting 0.0 (Low Logic) â†’ Intuition ÑƒÑĞ¸Ğ»ĞµĞ½Ğ° (1.5x)
        pace_setting 1.0 (High Logic) â†’ Intuition Ğ¾ÑĞ»Ğ°Ğ±Ğ»ĞµĞ½Ğ° (0.5x)
        """
        return 1.5 - (sliders.pace_setting * 1.0)

class AmygdalaAgent(BaseAgent):
    """
    ğŸ›¡ï¸ Amygdala (Safety & Boundaries)
    Scans input for threats, aggression, or violations.
    Activates Fight/Flight response.
    """
    agent_type = AgentType.AMYGDALA
    
    @property
    def style_instruction(self) -> str:
        return "...but maintain firm boundaries and safety."
    
    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        # Legacy single mode (backup)
        sys = "You are AMYGDALA. Detect threats (8-10) or safety (0-2)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction # NEW (manual set for legacy path)
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 1.5 - (sliders.risk_tolerance * 1.2)

class PrefrontalAgent(BaseAgent):
    """
    ğŸ§  Prefrontal Cortex (Logic & Control)
    Responsible for structured reasoning, planning, and factual accuracy.
    Inhibits impulsive responses.
    """
    agent_type = AgentType.PREFRONTAL
    
    @property
    def style_instruction(self) -> str:
        return "...but ensure the answer is logical, structured, and fact-based."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        sys = "You are LOGIC. Detect tasks/facts (8-10) or chat (0-2)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        """
        âœ¨ ĞĞĞ’ĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: ĞŸÑ€ÑĞ¼Ğ°Ñ ÑĞ²ÑĞ·ÑŒ Ñ pace_setting.
        pace_setting 0.0 (Low Logic) â†’ Logic Ğ¾ÑĞ»Ğ°Ğ±Ğ»ĞµĞ½Ğ° (0.7x)
        pace_setting 1.0 (High Logic) â†’ Logic ÑƒÑĞ¸Ğ»ĞµĞ½Ğ° (1.5x)
        
        Ğ’ĞĞ–ĞĞ: empathy_bias Ğ±Ğ¾Ğ»ÑŒÑˆĞµ ĞĞ• Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Logic Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ.
        Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Logic ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡ĞµÑ€ĞµĞ· pace_setting.
        """
        return 0.7 + (sliders.pace_setting * 0.8)

class SocialAgent(BaseAgent):
    """
    ğŸ¤ Social Cortex (Empathy & Norms)
    Manages relationships, politeness, and emotional resonance.
    Ensures social coherence.
    """
    agent_type = AgentType.SOCIAL
    
    @property
    def style_instruction(self) -> str:
        return "...but express it with warmth, politeness, and empathy."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        sys = "You are SOCIAL. Detect emotions/politeness (8-10)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 0.5 + sliders.empathy_bias

class StriatumAgent(BaseAgent):
    """
    ğŸ’ Striatum (Reward & Drive)
    Seeks novelty, engagement, and dopamine rewards.
    Drives playful and energetic responses.
    """
    agent_type = AgentType.STRIATUM
    
    @property
    def style_instruction(self) -> str:
        return "...but keep it playful, energetic, and engaging."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        sys = "You are REWARD. Detect fun/goals (8-10)."
        sig = await self.llm.generate_signal(sys, message.text, self.agent_type)
        sig.style_instruction = self.style_instruction
        return self._apply_modulation(sig, self._calculate_modifier(sliders))

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 0.5 + (sliders.risk_tolerance * 0.8)

class UncertaintyAgent(BaseAgent):
    """
    ğŸš¨ Uncertainty Agent (Lost State Handler) - Active Inference v2.0
    Activates when Prediction Error (PE) exceeds a threshold controlled by user settings.
    Implements 'Persistence' (Willpower) logic:
    - High Persistence: Bot ignores errors (Stubborn).
    - Low Persistence: Bot yields to errors (Flexible).
    """
    agent_type = AgentType.UNCERTAINTY
    
    @property
    def style_instruction(self) -> str:
        return "...but admit you are confused and ask clarifying questions."

    async def process(self, message: IncomingMessage, context: Dict, sliders: PersonalitySliders) -> AgentSignal:
        """
        Decides activation based on PE, Threshold, and Persistence.
        """
        # 1. Get Prediction Error (PE)
        prediction_error = context.get("prediction_error", 0.0)
        
        # 2. Get Thresholds from Sliders (Active Inference Control)
        # Default to high threshold if slider missing (safe fallback)
        pe_threshold = getattr(sliders, "pred_threshold", 0.8) 
        persistence = getattr(sliders, "persistence", 0.5)
        
        score = 0.0
        rationale = "In sync"
        confidence = 0.1
        
        # 3. Active Inference Logic: Willpower Check
        # If Persistence is HIGH, we artificially LOWER the perceived error.
        # "I'm sure I'm right, the user is just weird."
        perceived_error = prediction_error * (1.0 - (persistence * 0.5)) 
        
        if perceived_error >= pe_threshold:
            # --- LOST TRACK (Surprise Minimization Failed) ---
            score = 8.5
            confidence = 0.9
            rationale = f"High PE ({prediction_error:.2f}) > Threshold ({pe_threshold:.2f}). Persistence failed."
            
            # Critical failure escalation
            if prediction_error > 0.95:
                score = 10.0
                rationale += " [CRITICAL SURPRISE]"
                
        else:
            # --- IN SYNC (or Stubbornly Ignoring) ---
            score = 0.0
            confidence = 0.1
            if prediction_error > pe_threshold:
                rationale = f"High PE ({prediction_error:.2f}) suppressed by Persistence ({persistence:.2f})"
            else:
                rationale = f"Low PE ({prediction_error:.2f})"

        signal = AgentSignal(
            agent_name=self.agent_type,
            score=score,
            rationale_short=rationale,
            confidence=confidence,
            latency_ms=1, 
            style_instruction=self.style_instruction
        )
        return signal

    def _calculate_modifier(self, sliders: PersonalitySliders) -> float:
        return 1.0
